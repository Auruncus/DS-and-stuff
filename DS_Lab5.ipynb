{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS-Lab5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOTZmo7tOCD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbca6cb9-de65-4fbe-fae0-59d5ef4c3651"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import normalize\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsiANt2upFYR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f09b58bd-59d7-45a4-de57-1df1d12b1817"
      },
      "source": [
        "cd /content/gdrive/'My Drive'/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxEeY4kIpMTI",
        "colab_type": "text"
      },
      "source": [
        "# **Лабораторная работа №5**\n",
        "\n",
        "**Максимов Антон 17ПМИ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSWQINLDpPNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainQ = pd.read_csv('trainQ.csv')\n",
        "trainO = pd.read_csv('trainO.csv')\n",
        "testQ  = pd.read_csv('testQ.csv')\n",
        "testO  = pd.read_csv('testO.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UakFFP9WXRX",
        "colab_type": "text"
      },
      "source": [
        "**Нормализуем данные**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUf07-3xqPSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pixels_trainQ = normalize(trainQ.to_numpy())\n",
        "pixels_trainO = normalize(trainO.to_numpy())\n",
        "pixels_testQ = normalize(testQ.to_numpy())\n",
        "pixels_testO = normalize(testO.to_numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFSz04YCtEWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d37e934a-46c9-4600-b07d-835d2c2b2248"
      },
      "source": [
        "plt.imshow(pixels_testO[306].reshape((28, 28)).T, cmap='gray')"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1f7c9a22e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBOEHcjE/wHsgYdwWrXUpwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKDmQBS7Wbai",
        "colab_type": "text"
      },
      "source": [
        "**Соеденим 4 файла в train train_datasetQO и test_datasetQO, добавим лэйблы для Q - 1 , для O - 0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0XgKyDKNZW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataQ = np.hstack((np.asarray(pixels_trainQ), np.ones((np.asarray(pixels_trainQ).shape[0], 1), dtype=np.asarray(pixels_trainQ).dtype)))\n",
        "train_dataO = np.hstack((np.asarray(pixels_trainO), np.zeros((np.asarray(pixels_trainO).shape[0], 1), dtype=np.asarray(pixels_trainO).dtype)))\n",
        "train_datasetQO = np.concatenate([train_dataQ, train_dataO])\n",
        "test_dataQ =  np.hstack((np.asarray(pixels_testQ), np.ones((np.asarray(pixels_testQ).shape[0], 1), dtype=np.asarray(pixels_testQ).dtype)))\n",
        "test_dataO =   np.hstack((np.asarray(pixels_testO), np.zeros((np.asarray(pixels_testO).shape[0], 1), dtype=np.asarray(pixels_testO).dtype)))\n",
        "test_datasetQO = np.concatenate([test_dataQ, test_dataO])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWFBIct3Q4Po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc9e7b97-90af-4463-e627-4c687812b21d"
      },
      "source": [
        "train_dataQ[:, 0:784].shape"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep9yv6zGLL-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pixels_trainQO_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXkIym-wuQS0",
        "colab_type": "text"
      },
      "source": [
        "##**KNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWtCIP3SAmEK",
        "colab_type": "text"
      },
      "source": [
        "**Кросс - валидация будет при подборе параметров, а пока просто посмотрим как ведет себя классфикатор**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6du4a3umso4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "25837a0c-c79a-45ea-b490-a365b10ac988"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = knn.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = knn.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9105\n",
            "ROC AUC: 0.951858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3_8QPWKW99y",
        "colab_type": "text"
      },
      "source": [
        "**Посмотрим результаты, если предсказывать Q или O по отедельности**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1OlqjNsWtwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ba5847f-e185-4962-c4b3-1f236e88944e"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = knn.predict(test_dataQ[:, 0:784])\n",
        "y_test = test_dataQ[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzt1A62tWAa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26f003f0-419c-42c9-9eac-b32eeb394272"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = knn.predict(test_dataO[:, 0:784])\n",
        "y_test = test_dataO[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upAU6eP3XRMD",
        "colab_type": "text"
      },
      "source": [
        "**Как и предполагалось, предсказывать легче букву O, как дальше и окажется, для всех классификатор**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoxLox9kkNaj",
        "colab_type": "text"
      },
      "source": [
        "###**Подбор параметров**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGxVXwOSXpqm",
        "colab_type": "text"
      },
      "source": [
        "**Будем подбирать оптимальное кол-во соседов, используя кросс-валидацию**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8LSDHjtFngQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1bc1c28-ef37-4b63-d5f1-22274ae83c78"
      },
      "source": [
        "for i in range(1,21):\n",
        "  for j in range(2, 9):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn_cv = cross_val_score(knn, train_datasetQO[:, 0:784], train_datasetQO[:, -1], cv=j)\n",
        "    #print(\"Cross Validation score with 2-fold cv =====>>>> \", str(knn_cv_2))\n",
        "    print(\"Cross-Validation with {} neighbors Mean_score with {}-fold cv =====>>>> {} \".format(i, j, str(knn_cv.mean())))"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation with 1 neighbors Mean_score with 2-fold cv =====>>>> 0.942 \n",
            "Cross-Validation with 1 neighbors Mean_score with 3-fold cv =====>>>> 0.9460118801436167 \n",
            "Cross-Validation with 1 neighbors Mean_score with 4-fold cv =====>>>> 0.9465 \n",
            "Cross-Validation with 1 neighbors Mean_score with 5-fold cv =====>>>> 0.9470000000000001 \n",
            "Cross-Validation with 1 neighbors Mean_score with 6-fold cv =====>>>> 0.946035639564245 \n",
            "Cross-Validation with 1 neighbors Mean_score with 7-fold cv =====>>>> 0.9465288232893866 \n",
            "Cross-Validation with 1 neighbors Mean_score with 8-fold cv =====>>>> 0.945 \n",
            "Cross-Validation with 2 neighbors Mean_score with 2-fold cv =====>>>> 0.9105000000000001 \n",
            "Cross-Validation with 2 neighbors Mean_score with 3-fold cv =====>>>> 0.9190028351704997 \n",
            "Cross-Validation with 2 neighbors Mean_score with 4-fold cv =====>>>> 0.92 \n",
            "Cross-Validation with 2 neighbors Mean_score with 5-fold cv =====>>>> 0.917 \n",
            "Cross-Validation with 2 neighbors Mean_score with 6-fold cv =====>>>> 0.9200153909049371 \n",
            "Cross-Validation with 2 neighbors Mean_score with 7-fold cv =====>>>> 0.9205125860055439 \n",
            "Cross-Validation with 2 neighbors Mean_score with 8-fold cv =====>>>> 0.921 \n",
            "Cross-Validation with 3 neighbors Mean_score with 2-fold cv =====>>>> 0.935 \n",
            "Cross-Validation with 3 neighbors Mean_score with 3-fold cv =====>>>> 0.9365083646520773 \n",
            "Cross-Validation with 3 neighbors Mean_score with 4-fold cv =====>>>> 0.9385 \n",
            "Cross-Validation with 3 neighbors Mean_score with 5-fold cv =====>>>> 0.9410000000000001 \n",
            "Cross-Validation with 3 neighbors Mean_score with 6-fold cv =====>>>> 0.9400235673231849 \n",
            "Cross-Validation with 3 neighbors Mean_score with 7-fold cv =====>>>> 0.9420122131389735 \n",
            "Cross-Validation with 3 neighbors Mean_score with 8-fold cv =====>>>> 0.9405 \n",
            "Cross-Validation with 4 neighbors Mean_score with 2-fold cv =====>>>> 0.9155 \n",
            "Cross-Validation with 4 neighbors Mean_score with 3-fold cv =====>>>> 0.9150048251844659 \n",
            "Cross-Validation with 4 neighbors Mean_score with 4-fold cv =====>>>> 0.925 \n",
            "Cross-Validation with 4 neighbors Mean_score with 5-fold cv =====>>>> 0.9254999999999999 \n",
            "Cross-Validation with 4 neighbors Mean_score with 6-fold cv =====>>>> 0.926027463145997 \n",
            "Cross-Validation with 4 neighbors Mean_score with 7-fold cv =====>>>> 0.9270131277173531 \n",
            "Cross-Validation with 4 neighbors Mean_score with 8-fold cv =====>>>> 0.9265000000000001 \n",
            "Cross-Validation with 5 neighbors Mean_score with 2-fold cv =====>>>> 0.9285 \n",
            "Cross-Validation with 5 neighbors Mean_score with 3-fold cv =====>>>> 0.9325088561615509 \n",
            "Cross-Validation with 5 neighbors Mean_score with 4-fold cv =====>>>> 0.9365000000000001 \n",
            "Cross-Validation with 5 neighbors Mean_score with 5-fold cv =====>>>> 0.9365 \n",
            "Cross-Validation with 5 neighbors Mean_score with 6-fold cv =====>>>> 0.9385355794435227 \n",
            "Cross-Validation with 5 neighbors Mean_score with 7-fold cv =====>>>> 0.9400212463592746 \n",
            "Cross-Validation with 5 neighbors Mean_score with 8-fold cv =====>>>> 0.9410000000000001 \n",
            "Cross-Validation with 6 neighbors Mean_score with 2-fold cv =====>>>> 0.914 \n",
            "Cross-Validation with 6 neighbors Mean_score with 3-fold cv =====>>>> 0.9180033326739915 \n",
            "Cross-Validation with 6 neighbors Mean_score with 4-fold cv =====>>>> 0.9229999999999999 \n",
            "Cross-Validation with 6 neighbors Mean_score with 5-fold cv =====>>>> 0.925 \n",
            "Cross-Validation with 6 neighbors Mean_score with 6-fold cv =====>>>> 0.9240314551619652 \n",
            "Cross-Validation with 6 neighbors Mean_score with 7-fold cv =====>>>> 0.9285221820433087 \n",
            "Cross-Validation with 6 neighbors Mean_score with 8-fold cv =====>>>> 0.927 \n",
            "Cross-Validation with 7 neighbors Mean_score with 2-fold cv =====>>>> 0.925 \n",
            "Cross-Validation with 7 neighbors Mean_score with 3-fold cv =====>>>> 0.9290068511625398 \n",
            "Cross-Validation with 7 neighbors Mean_score with 4-fold cv =====>>>> 0.9325000000000001 \n",
            "Cross-Validation with 7 neighbors Mean_score with 5-fold cv =====>>>> 0.9350000000000002 \n",
            "Cross-Validation with 7 neighbors Mean_score with 6-fold cv =====>>>> 0.9370385734554986 \n",
            "Cross-Validation with 7 neighbors Mean_score with 7-fold cv =====>>>> 0.9380232443612726 \n",
            "Cross-Validation with 7 neighbors Mean_score with 8-fold cv =====>>>> 0.938 \n",
            "Cross-Validation with 8 neighbors Mean_score with 2-fold cv =====>>>> 0.909 \n",
            "Cross-Validation with 8 neighbors Mean_score with 3-fold cv =====>>>> 0.9165063266859673 \n",
            "Cross-Validation with 8 neighbors Mean_score with 4-fold cv =====>>>> 0.918 \n",
            "Cross-Validation with 8 neighbors Mean_score with 5-fold cv =====>>>> 0.9225 \n",
            "Cross-Validation with 8 neighbors Mean_score with 6-fold cv =====>>>> 0.9230184209893467 \n",
            "Cross-Validation with 8 neighbors Mean_score with 7-fold cv =====>>>> 0.9255005557822459 \n",
            "Cross-Validation with 8 neighbors Mean_score with 8-fold cv =====>>>> 0.9239999999999999 \n",
            "Cross-Validation with 9 neighbors Mean_score with 2-fold cv =====>>>> 0.9185000000000001 \n",
            "Cross-Validation with 9 neighbors Mean_score with 3-fold cv =====>>>> 0.9255048461635288 \n",
            "Cross-Validation with 9 neighbors Mean_score with 4-fold cv =====>>>> 0.924 \n",
            "Cross-Validation with 9 neighbors Mean_score with 5-fold cv =====>>>> 0.9279999999999999 \n",
            "Cross-Validation with 9 neighbors Mean_score with 6-fold cv =====>>>> 0.9290154630498041 \n",
            "Cross-Validation with 9 neighbors Mean_score with 7-fold cv =====>>>> 0.9305025959955537 \n",
            "Cross-Validation with 9 neighbors Mean_score with 8-fold cv =====>>>> 0.9325 \n",
            "Cross-Validation with 10 neighbors Mean_score with 2-fold cv =====>>>> 0.909 \n",
            "Cross-Validation with 10 neighbors Mean_score with 3-fold cv =====>>>> 0.9155053256849662 \n",
            "Cross-Validation with 10 neighbors Mean_score with 4-fold cv =====>>>> 0.9145 \n",
            "Cross-Validation with 10 neighbors Mean_score with 5-fold cv =====>>>> 0.9164999999999999 \n",
            "Cross-Validation with 10 neighbors Mean_score with 6-fold cv =====>>>> 0.9175173748887767 \n",
            "Cross-Validation with 10 neighbors Mean_score with 7-fold cv =====>>>> 0.9149969748561296 \n",
            "Cross-Validation with 10 neighbors Mean_score with 8-fold cv =====>>>> 0.9165 \n",
            "Cross-Validation with 11 neighbors Mean_score with 2-fold cv =====>>>> 0.9155 \n",
            "Cross-Validation with 11 neighbors Mean_score with 3-fold cv =====>>>> 0.9235028441615268 \n",
            "Cross-Validation with 11 neighbors Mean_score with 4-fold cv =====>>>> 0.9235000000000001 \n",
            "Cross-Validation with 11 neighbors Mean_score with 5-fold cv =====>>>> 0.924 \n",
            "Cross-Validation with 11 neighbors Mean_score with 6-fold cv =====>>>> 0.92451242094125 \n",
            "Cross-Validation with 11 neighbors Mean_score with 7-fold cv =====>>>> 0.9239950190654416 \n",
            "Cross-Validation with 11 neighbors Mean_score with 8-fold cv =====>>>> 0.9259999999999999 \n",
            "Cross-Validation with 12 neighbors Mean_score with 2-fold cv =====>>>> 0.9045000000000001 \n",
            "Cross-Validation with 12 neighbors Mean_score with 3-fold cv =====>>>> 0.9110053166939395 \n",
            "Cross-Validation with 12 neighbors Mean_score with 4-fold cv =====>>>> 0.913 \n",
            "Cross-Validation with 12 neighbors Mean_score with 5-fold cv =====>>>> 0.9149999999999998 \n",
            "Cross-Validation with 12 neighbors Mean_score with 6-fold cv =====>>>> 0.9140123367722387 \n",
            "Cross-Validation with 12 neighbors Mean_score with 7-fold cv =====>>>> 0.9149934572469783 \n",
            "Cross-Validation with 12 neighbors Mean_score with 8-fold cv =====>>>> 0.916 \n",
            "Cross-Validation with 13 neighbors Mean_score with 2-fold cv =====>>>> 0.909 \n",
            "Cross-Validation with 13 neighbors Mean_score with 3-fold cv =====>>>> 0.9175088261914609 \n",
            "Cross-Validation with 13 neighbors Mean_score with 4-fold cv =====>>>> 0.9205000000000001 \n",
            "Cross-Validation with 13 neighbors Mean_score with 5-fold cv =====>>>> 0.921 \n",
            "Cross-Validation with 13 neighbors Mean_score with 6-fold cv =====>>>> 0.9190113748406801 \n",
            "Cross-Validation with 13 neighbors Mean_score with 7-fold cv =====>>>> 0.9219899818491368 \n",
            "Cross-Validation with 13 neighbors Mean_score with 8-fold cv =====>>>> 0.9225 \n",
            "Cross-Validation with 14 neighbors Mean_score with 2-fold cv =====>>>> 0.8985000000000001 \n",
            "Cross-Validation with 14 neighbors Mean_score with 3-fold cv =====>>>> 0.9070043096989204 \n",
            "Cross-Validation with 14 neighbors Mean_score with 4-fold cv =====>>>> 0.9135 \n",
            "Cross-Validation with 14 neighbors Mean_score with 5-fold cv =====>>>> 0.9145000000000001 \n",
            "Cross-Validation with 14 neighbors Mean_score with 6-fold cv =====>>>> 0.9150133468003752 \n",
            "Cross-Validation with 14 neighbors Mean_score with 7-fold cv =====>>>> 0.9129919376398251 \n",
            "Cross-Validation with 14 neighbors Mean_score with 8-fold cv =====>>>> 0.9175 \n",
            "Cross-Validation with 15 neighbors Mean_score with 2-fold cv =====>>>> 0.9085000000000001 \n",
            "Cross-Validation with 15 neighbors Mean_score with 3-fold cv =====>>>> 0.9140113167059276 \n",
            "Cross-Validation with 15 neighbors Mean_score with 4-fold cv =====>>>> 0.9195000000000001 \n",
            "Cross-Validation with 15 neighbors Mean_score with 5-fold cv =====>>>> 0.9199999999999999 \n",
            "Cross-Validation with 15 neighbors Mean_score with 6-fold cv =====>>>> 0.9195163889089292 \n",
            "Cross-Validation with 15 neighbors Mean_score with 7-fold cv =====>>>> 0.9209944984592873 \n",
            "Cross-Validation with 15 neighbors Mean_score with 8-fold cv =====>>>> 0.9225 \n",
            "Cross-Validation with 16 neighbors Mean_score with 2-fold cv =====>>>> 0.897 \n",
            "Cross-Validation with 16 neighbors Mean_score with 3-fold cv =====>>>> 0.9060078042113971 \n",
            "Cross-Validation with 16 neighbors Mean_score with 4-fold cv =====>>>> 0.909 \n",
            "Cross-Validation with 16 neighbors Mean_score with 5-fold cv =====>>>> 0.9105000000000001 \n",
            "Cross-Validation with 16 neighbors Mean_score with 6-fold cv =====>>>> 0.9105223288363032 \n",
            "Cross-Validation with 16 neighbors Mean_score with 7-fold cv =====>>>> 0.911992936640824 \n",
            "Cross-Validation with 16 neighbors Mean_score with 8-fold cv =====>>>> 0.9115 \n",
            "Cross-Validation with 17 neighbors Mean_score with 2-fold cv =====>>>> 0.9025000000000001 \n",
            "Cross-Validation with 17 neighbors Mean_score with 3-fold cv =====>>>> 0.9090063117009225 \n",
            "Cross-Validation with 17 neighbors Mean_score with 4-fold cv =====>>>> 0.9155 \n",
            "Cross-Validation with 17 neighbors Mean_score with 5-fold cv =====>>>> 0.9164999999999999 \n",
            "Cross-Validation with 17 neighbors Mean_score with 6-fold cv =====>>>> 0.9180163768847845 \n",
            "Cross-Validation with 17 neighbors Mean_score with 7-fold cv =====>>>> 0.9179939778531327 \n",
            "Cross-Validation with 17 neighbors Mean_score with 8-fold cv =====>>>> 0.9185 \n",
            "Cross-Validation with 18 neighbors Mean_score with 2-fold cv =====>>>> 0.894 \n",
            "Cross-Validation with 18 neighbors Mean_score with 3-fold cv =====>>>> 0.9050038062014111 \n",
            "Cross-Validation with 18 neighbors Mean_score with 4-fold cv =====>>>> 0.91 \n",
            "Cross-Validation with 18 neighbors Mean_score with 5-fold cv =====>>>> 0.9085000000000001 \n",
            "Cross-Validation with 18 neighbors Mean_score with 6-fold cv =====>>>> 0.9075162927157733 \n",
            "Cross-Validation with 18 neighbors Mean_score with 7-fold cv =====>>>> 0.909994934642822 \n",
            "Cross-Validation with 18 neighbors Mean_score with 8-fold cv =====>>>> 0.9119999999999999 \n",
            "Cross-Validation with 19 neighbors Mean_score with 2-fold cv =====>>>> 0.8985000000000001 \n",
            "Cross-Validation with 19 neighbors Mean_score with 3-fold cv =====>>>> 0.9065053077029126 \n",
            "Cross-Validation with 19 neighbors Mean_score with 4-fold cv =====>>>> 0.914 \n",
            "Cross-Validation with 19 neighbors Mean_score with 5-fold cv =====>>>> 0.9120000000000001 \n",
            "Cross-Validation with 19 neighbors Mean_score with 6-fold cv =====>>>> 0.9145173508404877 \n",
            "Cross-Validation with 19 neighbors Mean_score with 7-fold cv =====>>>> 0.9150004924652811 \n",
            "Cross-Validation with 19 neighbors Mean_score with 8-fold cv =====>>>> 0.9165 \n",
            "Cross-Validation with 20 neighbors Mean_score with 2-fold cv =====>>>> 0.8925000000000001 \n",
            "Cross-Validation with 20 neighbors Mean_score with 3-fold cv =====>>>> 0.9040073007138876 \n",
            "Cross-Validation with 20 neighbors Mean_score with 4-fold cv =====>>>> 0.909 \n",
            "Cross-Validation with 20 neighbors Mean_score with 5-fold cv =====>>>> 0.9055000000000002 \n",
            "Cross-Validation with 20 neighbors Mean_score with 6-fold cv =====>>>> 0.9085173027439096 \n",
            "Cross-Validation with 20 neighbors Mean_score with 7-fold cv =====>>>> 0.9069944140366675 \n",
            "Cross-Validation with 20 neighbors Mean_score with 8-fold cv =====>>>> 0.9085000000000001 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq_nxC6UX_tG",
        "colab_type": "text"
      },
      "source": [
        "**Протестируем, при кол-во соседов = 1**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPIkyFA8yhND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b2bb2f62-d746-43eb-82ca-e77b90ada7c8"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = knn.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = knn.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9345\n",
            "ROC AUC: 0.9345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71RPyYS8YXr8",
        "colab_type": "text"
      },
      "source": [
        "**Увеличение точности до 0.9345**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgAvI_P8xOJo",
        "colab_type": "text"
      },
      "source": [
        "###**Дополнительно**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLMn09MW0167",
        "colab_type": "text"
      },
      "source": [
        "Для KNN найти примеры ошибочной классификации и показать ближайших соседей, объяснить почему была совершена ошибка."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNgwZLuDG6ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9f39781a-4dfc-4234-9c85-66c11808282f"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = knn.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = knn.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9345\n",
            "ROC AUC: 0.9345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsMGjz20YkUZ",
        "colab_type": "text"
      },
      "source": [
        "**Найдем индексы объектов, где была соврешена ошибка**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsUQuZ-VxKyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "17e828a2-c278-4c44-df28-2bac148eb801"
      },
      "source": [
        "counter = 6 #6 примеров\n",
        "for i in range(0,len(y_test)):\n",
        "  if y_test[i]!=y_pred[i]:\n",
        "    print(i)\n",
        "    counter-=1\n",
        "    if counter==0:\n",
        "      break  \n"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "13\n",
            "24\n",
            "30\n",
            "31\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxZMzmCFYt5p",
        "colab_type": "text"
      },
      "source": [
        "**Выберем 24**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM280uFi3Vt8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bca1e39-0578-4b48-9d02-6fd97a5320fb"
      },
      "source": [
        "test_datasetQO[24][0:784].shape"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLu1xc_c3iFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "dea95a7e-3f41-4377-cc7e-09a9718173de"
      },
      "source": [
        "print(y_pred[13],\" \", y_test[13])\n",
        "plt.imshow(test_datasetQO[13][0:784].reshape((28, 28)).T, cmap='gray')"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0   1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1f7c97ea90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN_USsG6E5sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "closest_distances, indices = knn.kneighbors(test_datasetQO[:, 0:784], n_neighbors=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdV_hwsrF9T9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "669ea849-0f02-456f-cf3f-3dcde2cfea5f"
      },
      "source": [
        "closest_distances[13], indices[13]"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.54298257, 0.59718675, 0.60875624]), array([1574,  783,  335]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjc6mihjGXgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "7def55c1-a653-43ec-ece4-4876759b1823"
      },
      "source": [
        "print(y_pred[1574],\" \", y_test[1574])\n",
        "plt.imshow(test_datasetQO[1574][0:784].reshape((28, 28)).T, cmap='gray')"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0   0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1f7d046898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7ERO/D90Trbzkz1U5AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0nqjxLYHjwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "df962609-d343-4017-c34b-850dba3ce2cb"
      },
      "source": [
        "print(y_pred[783],\" \", y_test[783])\n",
        "plt.imshow(test_datasetQO[783][0:784].reshape((28, 28)).T, cmap='gray')"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0   1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1f7d08a518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9mIiJlnHlgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "a8572dcd-0ecd-4cef-d6c5-8a030988bf9d"
      },
      "source": [
        "print(y_pred[335],\" \", y_test[335])\n",
        "plt.imshow(test_datasetQO[335][0:784].reshape((28, 28)).T, cmap='gray')"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0   1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1f7c887b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFGPKnQ0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8hoT4x7I4OI",
        "colab_type": "text"
      },
      "source": [
        "**Итак, по-моему ошибка была совершена, вследствие того что \"хвост\" Q располагался ближе внутрь, данное предположение подтверждается 3-м соседом, который был определен правильно, и у которого \"хвост\" явно выпирает**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_np2QcGFFpYC",
        "colab_type": "text"
      },
      "source": [
        "##**Дерево решений**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0MnHs8kFx2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQOc5oLKcLgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "40e2dc2e-e513-49d0-9a99-e20da446f128"
      },
      "source": [
        "DecTree = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "DecTree.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = DecTree.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = DecTree.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8675\n",
            "ROC AUC: 0.8973194999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYfkW2Lqe4sa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b9b5868-1710-4db7-d377-487239f8ce34"
      },
      "source": [
        "DecTree = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "DecTree.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = DecTree.predict(test_dataQ[:, 0:784])\n",
        "y_test = test_dataQ[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3UsanQMfiSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "677d9c86-183b-4a85-d3a7-a4bd669e4f79"
      },
      "source": [
        "DecTree = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "DecTree.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = DecTree.predict(test_dataO[:, 0:784])\n",
        "y_test = test_dataO[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCKLFuSBlofT",
        "colab_type": "text"
      },
      "source": [
        "###**Подбор параметров**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Q6yp37h9qC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10fb0dbb-91d0-455b-9ea2-cde56c85fd72"
      },
      "source": [
        "for i in range(1,21):\n",
        "  for j in range(2, 9):\n",
        "    DecTree = DecisionTreeClassifier(criterion='entropy', max_depth=i)\n",
        "    DecT = cross_val_score(DecTree, train_datasetQO[:, 0:784], train_datasetQO[:, -1], cv=j)\n",
        "    print(\"Cross-Validation with {} max_depth Mean_score with {}-fold cv =====>>>> {} \".format(i, j, str(DecT.mean())))"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation with 1 max_depth Mean_score with 2-fold cv =====>>>> 0.827 \n",
            "Cross-Validation with 1 max_depth Mean_score with 3-fold cv =====>>>> 0.8339911768055481 \n",
            "Cross-Validation with 1 max_depth Mean_score with 4-fold cv =====>>>> 0.82 \n",
            "Cross-Validation with 1 max_depth Mean_score with 5-fold cv =====>>>> 0.835 \n",
            "Cross-Validation with 1 max_depth Mean_score with 6-fold cv =====>>>> 0.8344966693119784 \n",
            "Cross-Validation with 1 max_depth Mean_score with 7-fold cv =====>>>> 0.8344824189894613 \n",
            "Cross-Validation with 1 max_depth Mean_score with 8-fold cv =====>>>> 0.835 \n",
            "Cross-Validation with 2 max_depth Mean_score with 2-fold cv =====>>>> 0.875 \n",
            "Cross-Validation with 2 max_depth Mean_score with 3-fold cv =====>>>> 0.8764992537447628 \n",
            "Cross-Validation with 2 max_depth Mean_score with 4-fold cv =====>>>> 0.883 \n",
            "Cross-Validation with 2 max_depth Mean_score with 5-fold cv =====>>>> 0.8870000000000001 \n",
            "Cross-Validation with 2 max_depth Mean_score with 6-fold cv =====>>>> 0.8800381165380083 \n",
            "Cross-Validation with 2 max_depth Mean_score with 7-fold cv =====>>>> 0.8870108764474962 \n",
            "Cross-Validation with 2 max_depth Mean_score with 8-fold cv =====>>>> 0.8885000000000001 \n",
            "Cross-Validation with 3 max_depth Mean_score with 2-fold cv =====>>>> 0.897 \n",
            "Cross-Validation with 3 max_depth Mean_score with 3-fold cv =====>>>> 0.8985002967038894 \n",
            "Cross-Validation with 3 max_depth Mean_score with 4-fold cv =====>>>> 0.9045000000000001 \n",
            "Cross-Validation with 3 max_depth Mean_score with 5-fold cv =====>>>> 0.9020000000000001 \n",
            "Cross-Validation with 3 max_depth Mean_score with 6-fold cv =====>>>> 0.8970372507996056 \n",
            "Cross-Validation with 3 max_depth Mean_score with 7-fold cv =====>>>> 0.9030054452589663 \n",
            "Cross-Validation with 3 max_depth Mean_score with 8-fold cv =====>>>> 0.899 \n",
            "Cross-Validation with 4 max_depth Mean_score with 2-fold cv =====>>>> 0.9225000000000001 \n",
            "Cross-Validation with 4 max_depth Mean_score with 3-fold cv =====>>>> 0.9174923426420433 \n",
            "Cross-Validation with 4 max_depth Mean_score with 4-fold cv =====>>>> 0.9245 \n",
            "Cross-Validation with 4 max_depth Mean_score with 5-fold cv =====>>>> 0.9245000000000001 \n",
            "Cross-Validation with 4 max_depth Mean_score with 6-fold cv =====>>>> 0.9250294591539813 \n",
            "Cross-Validation with 4 max_depth Mean_score with 7-fold cv =====>>>> 0.9215186222228474 \n",
            "Cross-Validation with 4 max_depth Mean_score with 8-fold cv =====>>>> 0.9199999999999999 \n",
            "Cross-Validation with 5 max_depth Mean_score with 2-fold cv =====>>>> 0.925 \n",
            "Cross-Validation with 5 max_depth Mean_score with 3-fold cv =====>>>> 0.9304978631325937 \n",
            "Cross-Validation with 5 max_depth Mean_score with 4-fold cv =====>>>> 0.9305 \n",
            "Cross-Validation with 5 max_depth Mean_score with 5-fold cv =====>>>> 0.9335000000000001 \n",
            "Cross-Validation with 5 max_depth Mean_score with 6-fold cv =====>>>> 0.9295264891902941 \n",
            "Cross-Validation with 5 max_depth Mean_score with 7-fold cv =====>>>> 0.9325146684301614 \n",
            "Cross-Validation with 5 max_depth Mean_score with 8-fold cv =====>>>> 0.936 \n",
            "Cross-Validation with 6 max_depth Mean_score with 2-fold cv =====>>>> 0.918 \n",
            "Cross-Validation with 6 max_depth Mean_score with 3-fold cv =====>>>> 0.9285003566440692 \n",
            "Cross-Validation with 6 max_depth Mean_score with 4-fold cv =====>>>> 0.9339999999999999 \n",
            "Cross-Validation with 6 max_depth Mean_score with 5-fold cv =====>>>> 0.931 \n",
            "Cross-Validation with 6 max_depth Mean_score with 6-fold cv =====>>>> 0.9345405574393383 \n",
            "Cross-Validation with 6 max_depth Mean_score with 7-fold cv =====>>>> 0.9315156674311603 \n",
            "Cross-Validation with 6 max_depth Mean_score with 8-fold cv =====>>>> 0.9355 \n",
            "Cross-Validation with 7 max_depth Mean_score with 2-fold cv =====>>>> 0.9245000000000001 \n",
            "Cross-Validation with 7 max_depth Mean_score with 3-fold cv =====>>>> 0.9350113586640533 \n",
            "Cross-Validation with 7 max_depth Mean_score with 4-fold cv =====>>>> 0.9325000000000001 \n",
            "Cross-Validation with 7 max_depth Mean_score with 5-fold cv =====>>>> 0.9335000000000001 \n",
            "Cross-Validation with 7 max_depth Mean_score with 6-fold cv =====>>>> 0.9365395714594907 \n",
            "Cross-Validation with 7 max_depth Mean_score with 7-fold cv =====>>>> 0.9400177287501229 \n",
            "Cross-Validation with 7 max_depth Mean_score with 8-fold cv =====>>>> 0.9335 \n",
            "Cross-Validation with 8 max_depth Mean_score with 2-fold cv =====>>>> 0.9245000000000001 \n",
            "Cross-Validation with 8 max_depth Mean_score with 3-fold cv =====>>>> 0.9320038601475726 \n",
            "Cross-Validation with 8 max_depth Mean_score with 4-fold cv =====>>>> 0.9295 \n",
            "Cross-Validation with 8 max_depth Mean_score with 5-fold cv =====>>>> 0.932 \n",
            "Cross-Validation with 8 max_depth Mean_score with 6-fold cv =====>>>> 0.9300315032585432 \n",
            "Cross-Validation with 8 max_depth Mean_score with 7-fold cv =====>>>> 0.9380091739246669 \n",
            "Cross-Validation with 8 max_depth Mean_score with 8-fold cv =====>>>> 0.9319999999999999 \n",
            "Cross-Validation with 9 max_depth Mean_score with 2-fold cv =====>>>> 0.9205000000000001 \n",
            "Cross-Validation with 9 max_depth Mean_score with 3-fold cv =====>>>> 0.9349963736191281 \n",
            "Cross-Validation with 9 max_depth Mean_score with 4-fold cv =====>>>> 0.9325 \n",
            "Cross-Validation with 9 max_depth Mean_score with 5-fold cv =====>>>> 0.9355 \n",
            "Cross-Validation with 9 max_depth Mean_score with 6-fold cv =====>>>> 0.9365275473150084 \n",
            "Cross-Validation with 9 max_depth Mean_score with 7-fold cv =====>>>> 0.9375167086434691 \n",
            "Cross-Validation with 9 max_depth Mean_score with 8-fold cv =====>>>> 0.9415 \n",
            "Cross-Validation with 10 max_depth Mean_score with 2-fold cv =====>>>> 0.919 \n",
            "Cross-Validation with 10 max_depth Mean_score with 3-fold cv =====>>>> 0.937497377617138 \n",
            "Cross-Validation with 10 max_depth Mean_score with 4-fold cv =====>>>> 0.933 \n",
            "Cross-Validation with 10 max_depth Mean_score with 5-fold cv =====>>>> 0.9315 \n",
            "Cross-Validation with 10 max_depth Mean_score with 6-fold cv =====>>>> 0.9305395233629126 \n",
            "Cross-Validation with 10 max_depth Mean_score with 7-fold cv =====>>>> 0.9345197056464664 \n",
            "Cross-Validation with 10 max_depth Mean_score with 8-fold cv =====>>>> 0.9395 \n",
            "Cross-Validation with 11 max_depth Mean_score with 2-fold cv =====>>>> 0.9295 \n",
            "Cross-Validation with 11 max_depth Mean_score with 3-fold cv =====>>>> 0.9344943746141351 \n",
            "Cross-Validation with 11 max_depth Mean_score with 4-fold cv =====>>>> 0.9325 \n",
            "Cross-Validation with 11 max_depth Mean_score with 5-fold cv =====>>>> 0.93 \n",
            "Cross-Validation with 11 max_depth Mean_score with 6-fold cv =====>>>> 0.935027535290864 \n",
            "Cross-Validation with 11 max_depth Mean_score with 7-fold cv =====>>>> 0.9355151890363159 \n",
            "Cross-Validation with 11 max_depth Mean_score with 8-fold cv =====>>>> 0.937 \n",
            "Cross-Validation with 12 max_depth Mean_score with 2-fold cv =====>>>> 0.9235 \n",
            "Cross-Validation with 12 max_depth Mean_score with 3-fold cv =====>>>> 0.9319978661296027 \n",
            "Cross-Validation with 12 max_depth Mean_score with 4-fold cv =====>>>> 0.93 \n",
            "Cross-Validation with 12 max_depth Mean_score with 5-fold cv =====>>>> 0.9285 \n",
            "Cross-Validation with 12 max_depth Mean_score with 6-fold cv =====>>>> 0.9350305413269845 \n",
            "Cross-Validation with 12 max_depth Mean_score with 7-fold cv =====>>>> 0.9345232232556174 \n",
            "Cross-Validation with 12 max_depth Mean_score with 8-fold cv =====>>>> 0.935 \n",
            "Cross-Validation with 13 max_depth Mean_score with 2-fold cv =====>>>> 0.916 \n",
            "Cross-Validation with 13 max_depth Mean_score with 3-fold cv =====>>>> 0.9299988611365856 \n",
            "Cross-Validation with 13 max_depth Mean_score with 4-fold cv =====>>>> 0.9315 \n",
            "Cross-Validation with 13 max_depth Mean_score with 5-fold cv =====>>>> 0.9305 \n",
            "Cross-Validation with 13 max_depth Mean_score with 6-fold cv =====>>>> 0.9300345092946637 \n",
            "Cross-Validation with 13 max_depth Mean_score with 7-fold cv =====>>>> 0.9365106724261654 \n",
            "Cross-Validation with 13 max_depth Mean_score with 8-fold cv =====>>>> 0.9315 \n",
            "Cross-Validation with 14 max_depth Mean_score with 2-fold cv =====>>>> 0.9195 \n",
            "Cross-Validation with 14 max_depth Mean_score with 3-fold cv =====>>>> 0.9335053616490742 \n",
            "Cross-Validation with 14 max_depth Mean_score with 4-fold cv =====>>>> 0.935 \n",
            "Cross-Validation with 14 max_depth Mean_score with 5-fold cv =====>>>> 0.9339999999999999 \n",
            "Cross-Validation with 14 max_depth Mean_score with 6-fold cv =====>>>> 0.9305305052545512 \n",
            "Cross-Validation with 14 max_depth Mean_score with 7-fold cv =====>>>> 0.934509152819012 \n",
            "Cross-Validation with 14 max_depth Mean_score with 8-fold cv =====>>>> 0.929 \n",
            "Cross-Validation with 15 max_depth Mean_score with 2-fold cv =====>>>> 0.9275 \n",
            "Cross-Validation with 15 max_depth Mean_score with 3-fold cv =====>>>> 0.9320068571565577 \n",
            "Cross-Validation with 15 max_depth Mean_score with 4-fold cv =====>>>> 0.931 \n",
            "Cross-Validation with 15 max_depth Mean_score with 5-fold cv =====>>>> 0.9315000000000001 \n",
            "Cross-Validation with 15 max_depth Mean_score with 6-fold cv =====>>>> 0.935538561431354 \n",
            "Cross-Validation with 15 max_depth Mean_score with 7-fold cv =====>>>> 0.935508153818013 \n",
            "Cross-Validation with 15 max_depth Mean_score with 8-fold cv =====>>>> 0.937 \n",
            "Cross-Validation with 16 max_depth Mean_score with 2-fold cv =====>>>> 0.9245000000000001 \n",
            "Cross-Validation with 16 max_depth Mean_score with 3-fold cv =====>>>> 0.9354968741196285 \n",
            "Cross-Validation with 16 max_depth Mean_score with 4-fold cv =====>>>> 0.9295 \n",
            "Cross-Validation with 16 max_depth Mean_score with 5-fold cv =====>>>> 0.9339999999999999 \n",
            "Cross-Validation with 16 max_depth Mean_score with 6-fold cv =====>>>> 0.9350365533992256 \n",
            "Cross-Validation with 16 max_depth Mean_score with 7-fold cv =====>>>> 0.9395182282506225 \n",
            "Cross-Validation with 16 max_depth Mean_score with 8-fold cv =====>>>> 0.9355 \n",
            "Cross-Validation with 17 max_depth Mean_score with 2-fold cv =====>>>> 0.926 \n",
            "Cross-Validation with 17 max_depth Mean_score with 3-fold cv =====>>>> 0.9290038541535548 \n",
            "Cross-Validation with 17 max_depth Mean_score with 4-fold cv =====>>>> 0.934 \n",
            "Cross-Validation with 17 max_depth Mean_score with 5-fold cv =====>>>> 0.9315 \n",
            "Cross-Validation with 17 max_depth Mean_score with 6-fold cv =====>>>> 0.9385295673712816 \n",
            "Cross-Validation with 17 max_depth Mean_score with 7-fold cv =====>>>> 0.9385192272516215 \n",
            "Cross-Validation with 17 max_depth Mean_score with 8-fold cv =====>>>> 0.9325 \n",
            "Cross-Validation with 18 max_depth Mean_score with 2-fold cv =====>>>> 0.925 \n",
            "Cross-Validation with 18 max_depth Mean_score with 3-fold cv =====>>>> 0.9350053646460831 \n",
            "Cross-Validation with 18 max_depth Mean_score with 4-fold cv =====>>>> 0.93 \n",
            "Cross-Validation with 18 max_depth Mean_score with 5-fold cv =====>>>> 0.9339999999999999 \n",
            "Cross-Validation with 18 max_depth Mean_score with 6-fold cv =====>>>> 0.9310385253589207 \n",
            "Cross-Validation with 18 max_depth Mean_score with 7-fold cv =====>>>> 0.9335171870383138 \n",
            "Cross-Validation with 18 max_depth Mean_score with 8-fold cv =====>>>> 0.9335 \n",
            "Cross-Validation with 19 max_depth Mean_score with 2-fold cv =====>>>> 0.9195 \n",
            "Cross-Validation with 19 max_depth Mean_score with 3-fold cv =====>>>> 0.9324908741076405 \n",
            "Cross-Validation with 19 max_depth Mean_score with 4-fold cv =====>>>> 0.9325 \n",
            "Cross-Validation with 19 max_depth Mean_score with 5-fold cv =====>>>> 0.93 \n",
            "Cross-Validation with 19 max_depth Mean_score with 6-fold cv =====>>>> 0.9330285212707116 \n",
            "Cross-Validation with 19 max_depth Mean_score with 7-fold cv =====>>>> 0.9355187066454673 \n",
            "Cross-Validation with 19 max_depth Mean_score with 8-fold cv =====>>>> 0.9384999999999999 \n",
            "Cross-Validation with 20 max_depth Mean_score with 2-fold cv =====>>>> 0.9215 \n",
            "Cross-Validation with 20 max_depth Mean_score with 3-fold cv =====>>>> 0.9334933736131341 \n",
            "Cross-Validation with 20 max_depth Mean_score with 4-fold cv =====>>>> 0.9305000000000001 \n",
            "Cross-Validation with 20 max_depth Mean_score with 5-fold cv =====>>>> 0.9349999999999999 \n",
            "Cross-Validation with 20 max_depth Mean_score with 6-fold cv =====>>>> 0.9320305172786957 \n",
            "Cross-Validation with 20 max_depth Mean_score with 7-fold cv =====>>>> 0.9395217458597741 \n",
            "Cross-Validation with 20 max_depth Mean_score with 8-fold cv =====>>>> 0.9364999999999999 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmpVg5tGZCGT",
        "colab_type": "text"
      },
      "source": [
        "**Лучший результат с max_depth = 9**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKsd4pK5xVeI",
        "colab_type": "text"
      },
      "source": [
        "###**Дополнительно**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md3NxWti07_8",
        "colab_type": "text"
      },
      "source": [
        " Определить, по каким пикселям принимается решение и в чью пользу: O или Q."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P3X56O7xWte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "640afe9f-510d-4aab-cb5b-6abd33476a38"
      },
      "source": [
        "DecTree = DecisionTreeClassifier(criterion='entropy', max_depth=9)\n",
        "DecTree.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = DecTree.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = DecTree.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9315\n",
            "ROC AUC: 0.9315000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jUjpsDg4rwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_nodes = DecTree.tree_.node_count\n",
        "children_left = DecTree.tree_.children_left\n",
        "children_right = DecTree.tree_.children_right\n",
        "feature = DecTree.tree_.feature\n",
        "threshold = DecTree.tree_.threshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVU5tX2B46Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "node_indicator = DecTree.decision_path(test_datasetQO[:, 0:784])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o59EGc405Lw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "leave_id = DecTree.apply(test_datasetQO[:, 0:784])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kq7FqKc5oNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test_datasetQO[:, 0:784]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IzyXsf--B3n",
        "colab_type": "text"
      },
      "source": [
        "**Признаки по которым принимаются решения**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TINAgNNB7a9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "67e979bb-4c7c-41a2-e281-7253868f83b2"
      },
      "source": [
        "feature"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([407, 302, 433, 238, 495, 441,  -2,  -2,  -2, 528, 576,  -2,  -2,\n",
              "       153,  -2,  -2,  -2, 640, 352, 456, 304, 622,  -2,  -2, 386, 271,\n",
              "        -2,  -2, 530,  -2,  -2, 570, 209, 372, 413,  -2,  -2,  -2, 618,\n",
              "        -2,  -2,  -2, 513,  -2, 271, 652,  -2,  -2,  -2, 501,  -2, 631,\n",
              "       185,  -2,  -2,  -2, 423, 571, 595,  -2, 295,  -2,  -2, 430, 300,\n",
              "        -2, 249, 131,  -2,  -2,  -2, 242, 686, 320,  -2, 626,  -2,  -2,\n",
              "        -2,  -2, 219,  -2, 544,  -2, 442,  -2,  -2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQqOH9g87jF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "b2812eed-65df-4b0a-d2e2-cc85b4286645"
      },
      "source": [
        "print(y_pred[500],\" \", y_test[500])\n",
        "plt.imshow(test_datasetQO[500][0:784].reshape((28, 28)).T, cmap='gray')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0   1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff593885a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7EAiKDuQCMoOJIKyA4n4PxNdT+dgf7oVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keZblSG_5dJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f7cc94da-6e55-48a9-fbc3-9c12f4d527a5"
      },
      "source": [
        "sample_id = 500\n",
        "node_index = node_indicator.indices[node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]]\n",
        "print(\"Rules used to predict sample %s: \" % sample_id)\n",
        "for node_id in node_index:\n",
        "    if leave_id[sample_id] != node_id:\n",
        "        continue\n",
        "    if test[sample_id, feature[node_id]] <= threshold[node_id]:\n",
        "        threshold_sign = \"<=\"\n",
        "    else:\n",
        "        threshold_sign = \">\"\n",
        "    print(\"Decision id node %s : (X[%s, %s] (= %s) %s %s)\" % (node_id, sample_id, feature[node_id], test[sample_id, feature[node_id]], threshold_sign, threshold[node_id]))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rules used to predict sample 500: \n",
            "Decision id node 81 : (X[500, -2] (= 0.0) > -2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvIXiGuf-ssk",
        "colab_type": "text"
      },
      "source": [
        "**В данном случае решение принимаетсся в пользу Q по признаку 219  X[:, 219] <= 0.0287875784561038**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwVxH_ai-qhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "f379ce7f-95cf-4fbb-90f9-f7d00f373054"
      },
      "source": [
        "print(y_pred[1600],\" \", y_test[1600])\n",
        "plt.imshow(test_datasetQO[1600][0:784].reshape((28, 28)).T, cmap='gray')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0   0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff593238400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tPqsVJZ-6z5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55cbbdbb-e304-4520-88af-f38d151f0191"
      },
      "source": [
        "sample_id = 1600\n",
        "node_index = node_indicator.indices[node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]]\n",
        "print(\"Rules used to predict sample %s: \" % sample_id)\n",
        "for node_id in node_index:\n",
        "    if leave_id[sample_id] != node_id:\n",
        "        continue\n",
        "    if test[sample_id, feature[node_id]] <= threshold[node_id]:\n",
        "        threshold_sign = \"<=\"\n",
        "    else:\n",
        "        threshold_sign = \">\"\n",
        "    print(\"Decision id node %s : (X[%s, %s] (= %s) %s %s)\" % (node_id, sample_id, feature[node_id], test[sample_id, feature[node_id]], threshold_sign, threshold[node_id]))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rules used to predict sample 1600: \n",
            "Decision id node 41 : (X[1600, -2] (= 0.0) > -2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GQZH5Xo_liN",
        "colab_type": "text"
      },
      "source": [
        "**Здесь решение принимаетсся в пользу O по признаку 618  X[:, 618] <= 0.04611745569854975**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsz7CJXv_kiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlyCsTgB9qiH",
        "colab_type": "text"
      },
      "source": [
        "**Структура дерева**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75s5Xq-V8cm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0e3704b-16c7-4b2b-cd52-6b76e6bce4b7"
      },
      "source": [
        "node_depth = np.zeros(shape=n_nodes)\n",
        "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
        "stack = [(0, -1)]  \n",
        "while len(stack) > 0:\n",
        "    node_id, parent_depth = stack.pop()\n",
        "    node_depth[node_id] = parent_depth + 1\n",
        "\n",
        "    if children_left[node_id] != children_right[node_id]:\n",
        "        stack.append((children_left[node_id], parent_depth + 1))\n",
        "        stack.append((children_right[node_id], parent_depth + 1))\n",
        "    else:\n",
        "        is_leaves[node_id] = True\n",
        "print(\"The tree structure has %s nodes and has \" \"the following tree structure:\" % n_nodes)\n",
        "for i in range(n_nodes):\n",
        "    if is_leaves[i]:\n",
        "        print(\"%snode=%s leaf node.\" % (node_depth[i] , i))\n",
        "    else:\n",
        "        print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
        "            \"node %s.\" % (node_depth[i] , i, children_left[i], feature[i], threshold[i], children_right[i]))\n",
        "print()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tree structure has 87 nodes and has the following tree structure:\n",
            "0.0node=0 test node: go to node 1 if X[:, 407] <= 0.007881436264142394 else to node 56.\n",
            "1.0node=1 test node: go to node 2 if X[:, 302] <= 0.0002914859214797616 else to node 17.\n",
            "2.0node=2 test node: go to node 3 if X[:, 433] <= 0.009344716556370258 else to node 16.\n",
            "3.0node=3 test node: go to node 4 if X[:, 238] <= 0.02224053256213665 else to node 9.\n",
            "4.0node=4 test node: go to node 5 if X[:, 495] <= 0.0005647527286782861 else to node 8.\n",
            "5.0node=5 test node: go to node 6 if X[:, 441] <= 0.003612200729548931 else to node 7.\n",
            "6.0node=6 leaf node.\n",
            "6.0node=7 leaf node.\n",
            "5.0node=8 leaf node.\n",
            "4.0node=9 test node: go to node 10 if X[:, 528] <= 0.006405198248103261 else to node 13.\n",
            "5.0node=10 test node: go to node 11 if X[:, 576] <= 0.0018222358776256442 else to node 12.\n",
            "6.0node=11 leaf node.\n",
            "6.0node=12 leaf node.\n",
            "5.0node=13 test node: go to node 14 if X[:, 153] <= 0.07545606791973114 else to node 15.\n",
            "6.0node=14 leaf node.\n",
            "6.0node=15 leaf node.\n",
            "3.0node=16 leaf node.\n",
            "2.0node=17 test node: go to node 18 if X[:, 640] <= 0.00034115226299036294 else to node 49.\n",
            "3.0node=18 test node: go to node 19 if X[:, 352] <= 0.031268016435205936 else to node 42.\n",
            "4.0node=19 test node: go to node 20 if X[:, 456] <= 0.0001529154396848753 else to node 31.\n",
            "5.0node=20 test node: go to node 21 if X[:, 304] <= 0.00206720270216465 else to node 24.\n",
            "6.0node=21 test node: go to node 22 if X[:, 622] <= 0.0909418947994709 else to node 23.\n",
            "7.0node=22 leaf node.\n",
            "7.0node=23 leaf node.\n",
            "6.0node=24 test node: go to node 25 if X[:, 386] <= 0.05240803211927414 else to node 28.\n",
            "7.0node=25 test node: go to node 26 if X[:, 271] <= 0.00035590241895988584 else to node 27.\n",
            "8.0node=26 leaf node.\n",
            "8.0node=27 leaf node.\n",
            "7.0node=28 test node: go to node 29 if X[:, 530] <= 0.00031297371606342494 else to node 30.\n",
            "8.0node=29 leaf node.\n",
            "8.0node=30 leaf node.\n",
            "5.0node=31 test node: go to node 32 if X[:, 570] <= 0.009953314904123545 else to node 41.\n",
            "6.0node=32 test node: go to node 33 if X[:, 209] <= 0.004135605180636048 else to node 38.\n",
            "7.0node=33 test node: go to node 34 if X[:, 372] <= 0.08193200454115868 else to node 37.\n",
            "8.0node=34 test node: go to node 35 if X[:, 413] <= 0.0755191370844841 else to node 36.\n",
            "9.0node=35 leaf node.\n",
            "9.0node=36 leaf node.\n",
            "8.0node=37 leaf node.\n",
            "7.0node=38 test node: go to node 39 if X[:, 618] <= 0.04611745569854975 else to node 40.\n",
            "8.0node=39 leaf node.\n",
            "8.0node=40 leaf node.\n",
            "6.0node=41 leaf node.\n",
            "4.0node=42 test node: go to node 43 if X[:, 513] <= 0.009412475395947695 else to node 44.\n",
            "5.0node=43 leaf node.\n",
            "5.0node=44 test node: go to node 45 if X[:, 271] <= 0.04032775014638901 else to node 48.\n",
            "6.0node=45 test node: go to node 46 if X[:, 652] <= 0.05951715633273125 else to node 47.\n",
            "7.0node=46 leaf node.\n",
            "7.0node=47 leaf node.\n",
            "6.0node=48 leaf node.\n",
            "3.0node=49 test node: go to node 50 if X[:, 501] <= 0.0009009905916173011 else to node 51.\n",
            "4.0node=50 leaf node.\n",
            "4.0node=51 test node: go to node 52 if X[:, 631] <= 0.06856773421168327 else to node 55.\n",
            "5.0node=52 test node: go to node 53 if X[:, 185] <= 0.06989310309290886 else to node 54.\n",
            "6.0node=53 leaf node.\n",
            "6.0node=54 leaf node.\n",
            "5.0node=55 leaf node.\n",
            "1.0node=56 test node: go to node 57 if X[:, 423] <= 0.030904334038496017 else to node 80.\n",
            "2.0node=57 test node: go to node 58 if X[:, 571] <= 0.011097496375441551 else to node 63.\n",
            "3.0node=58 test node: go to node 59 if X[:, 595] <= 0.07652807235717773 else to node 60.\n",
            "4.0node=59 leaf node.\n",
            "4.0node=60 test node: go to node 61 if X[:, 295] <= 0.046942876651883125 else to node 62.\n",
            "5.0node=61 leaf node.\n",
            "5.0node=62 leaf node.\n",
            "3.0node=63 test node: go to node 64 if X[:, 430] <= 0.016842021606862545 else to node 71.\n",
            "4.0node=64 test node: go to node 65 if X[:, 300] <= 0.06689250469207764 else to node 66.\n",
            "5.0node=65 leaf node.\n",
            "5.0node=66 test node: go to node 67 if X[:, 249] <= 0.00016699303523637354 else to node 70.\n",
            "6.0node=67 test node: go to node 68 if X[:, 131] <= 0.09121460095047951 else to node 69.\n",
            "7.0node=68 leaf node.\n",
            "7.0node=69 leaf node.\n",
            "6.0node=70 leaf node.\n",
            "4.0node=71 test node: go to node 72 if X[:, 242] <= 0.05577428825199604 else to node 79.\n",
            "5.0node=72 test node: go to node 73 if X[:, 686] <= 0.000607790017966181 else to node 78.\n",
            "6.0node=73 test node: go to node 74 if X[:, 320] <= 0.07167313992977142 else to node 75.\n",
            "7.0node=74 leaf node.\n",
            "7.0node=75 test node: go to node 76 if X[:, 626] <= 0.04590754397213459 else to node 77.\n",
            "8.0node=76 leaf node.\n",
            "8.0node=77 leaf node.\n",
            "6.0node=78 leaf node.\n",
            "5.0node=79 leaf node.\n",
            "2.0node=80 test node: go to node 81 if X[:, 219] <= 0.0287875784561038 else to node 82.\n",
            "3.0node=81 leaf node.\n",
            "3.0node=82 test node: go to node 83 if X[:, 544] <= 0.06088424660265446 else to node 84.\n",
            "4.0node=83 leaf node.\n",
            "4.0node=84 test node: go to node 85 if X[:, 442] <= 0.0111374007537961 else to node 86.\n",
            "5.0node=85 leaf node.\n",
            "5.0node=86 leaf node.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8FjDcWFyT1",
        "colab_type": "text"
      },
      "source": [
        "##**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1sB37IbGIKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFB9TgEydcYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a7a1530-66f6-489f-9317-69991fdb41b4"
      },
      "source": [
        "RanFor = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=2)\n",
        "RanFor.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = RanFor.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = RanFor.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9155\n",
            "ROC AUC: 0.978051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUWI4WO9e66s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70237b09-04e0-4796-ea40-4b5aaea03396"
      },
      "source": [
        "RanFor = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=2)\n",
        "RanFor.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = RanFor.predict(test_dataQ[:, 0:784])\n",
        "y_test = test_dataQ[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc1CGti_fu6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a995522-601f-49d6-e763-26d2e625039a"
      },
      "source": [
        "RanFor = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=2)\n",
        "RanFor.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = RanFor.predict(test_dataO[:, 0:784])\n",
        "y_test = test_dataO[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k_8Zq8Blprt",
        "colab_type": "text"
      },
      "source": [
        "###**Подбор параметров**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyGqmbX4Zetb",
        "colab_type": "text"
      },
      "source": [
        "**Предыдущие классификаторы показали, что лучший score получается при cv=9**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yldsvT8elq9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3a2c52a-3a4a-4ff8-de2e-b7a7a45d0231"
      },
      "source": [
        "for i in range(20,221,20):\n",
        "  for j in range(1,15):\n",
        "    RanFor = RandomForestClassifier(n_estimators=i, criterion='entropy', max_depth=j)\n",
        "    RanF = cross_val_score(RanFor, train_datasetQO[:, 0:784], train_datasetQO[:, -1], cv=8)\n",
        "    print(\"Cross-Validation with {} n_estimators Mean_score with {} max_depth =====>>>> {} \".format(i, j, str(RanF.mean())))"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation with 20 n_estimators Mean_score with 1 max_depth =====>>>> 0.863 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 2 max_depth =====>>>> 0.9275 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 3 max_depth =====>>>> 0.9464999999999999 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 4 max_depth =====>>>> 0.9604999999999999 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 5 max_depth =====>>>> 0.968 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 6 max_depth =====>>>> 0.9715 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 7 max_depth =====>>>> 0.9735 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 8 max_depth =====>>>> 0.978 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 9 max_depth =====>>>> 0.975 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 10 max_depth =====>>>> 0.976 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 11 max_depth =====>>>> 0.972 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 12 max_depth =====>>>> 0.978 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 13 max_depth =====>>>> 0.9724999999999999 \n",
            "Cross-Validation with 20 n_estimators Mean_score with 14 max_depth =====>>>> 0.9775 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 1 max_depth =====>>>> 0.8645 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 2 max_depth =====>>>> 0.9219999999999999 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 3 max_depth =====>>>> 0.954 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 4 max_depth =====>>>> 0.9604999999999999 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 5 max_depth =====>>>> 0.9695 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 6 max_depth =====>>>> 0.9744999999999999 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 7 max_depth =====>>>> 0.9755 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 8 max_depth =====>>>> 0.975 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 9 max_depth =====>>>> 0.977 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 10 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 11 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 12 max_depth =====>>>> 0.9755 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 13 max_depth =====>>>> 0.9775 \n",
            "Cross-Validation with 40 n_estimators Mean_score with 14 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 1 max_depth =====>>>> 0.8634999999999999 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 2 max_depth =====>>>> 0.9349999999999999 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 3 max_depth =====>>>> 0.9515 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 4 max_depth =====>>>> 0.964 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 5 max_depth =====>>>> 0.9704999999999999 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 6 max_depth =====>>>> 0.974 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 7 max_depth =====>>>> 0.9775 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 8 max_depth =====>>>> 0.977 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 9 max_depth =====>>>> 0.977 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 10 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 11 max_depth =====>>>> 0.978 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 12 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 13 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 14 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 1 max_depth =====>>>> 0.859 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 2 max_depth =====>>>> 0.9259999999999999 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 3 max_depth =====>>>> 0.952 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 4 max_depth =====>>>> 0.9664999999999999 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 5 max_depth =====>>>> 0.9724999999999999 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 6 max_depth =====>>>> 0.9764999999999999 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 7 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 8 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 9 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 10 max_depth =====>>>> 0.9824999999999999 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 11 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 12 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 13 max_depth =====>>>> 0.977 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 14 max_depth =====>>>> 0.982 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 1 max_depth =====>>>> 0.8665 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 2 max_depth =====>>>> 0.9325 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 3 max_depth =====>>>> 0.9535 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 4 max_depth =====>>>> 0.9664999999999999 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 5 max_depth =====>>>> 0.975 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 6 max_depth =====>>>> 0.9755 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 7 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 8 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 9 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 10 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 11 max_depth =====>>>> 0.9824999999999999 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 12 max_depth =====>>>> 0.977 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 13 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 100 n_estimators Mean_score with 14 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 1 max_depth =====>>>> 0.872 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 2 max_depth =====>>>> 0.9355 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 3 max_depth =====>>>> 0.952 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 4 max_depth =====>>>> 0.967 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 5 max_depth =====>>>> 0.973 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 6 max_depth =====>>>> 0.9755 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 7 max_depth =====>>>> 0.9775 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 8 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 9 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 10 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 11 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 12 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 13 max_depth =====>>>> 0.981 \n",
            "Cross-Validation with 120 n_estimators Mean_score with 14 max_depth =====>>>> 0.9824999999999999 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 1 max_depth =====>>>> 0.865 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 2 max_depth =====>>>> 0.9325 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 3 max_depth =====>>>> 0.9515 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 4 max_depth =====>>>> 0.9684999999999999 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 5 max_depth =====>>>> 0.9755 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 6 max_depth =====>>>> 0.9764999999999999 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 7 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 8 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 9 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 10 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 11 max_depth =====>>>> 0.9815 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 12 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 13 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 140 n_estimators Mean_score with 14 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 1 max_depth =====>>>> 0.865 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 2 max_depth =====>>>> 0.9335 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 3 max_depth =====>>>> 0.953 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 4 max_depth =====>>>> 0.9664999999999999 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 5 max_depth =====>>>> 0.974 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 6 max_depth =====>>>> 0.9755 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 7 max_depth =====>>>> 0.978 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 8 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 9 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 10 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 11 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 12 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 13 max_depth =====>>>> 0.978 \n",
            "Cross-Validation with 160 n_estimators Mean_score with 14 max_depth =====>>>> 0.977 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 1 max_depth =====>>>> 0.861 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 2 max_depth =====>>>> 0.937 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 3 max_depth =====>>>> 0.9555 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 4 max_depth =====>>>> 0.9655 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 5 max_depth =====>>>> 0.973 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 6 max_depth =====>>>> 0.9775 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 7 max_depth =====>>>> 0.977 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 8 max_depth =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 9 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 10 max_depth =====>>>> 0.978 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 11 max_depth =====>>>> 0.9775 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 12 max_depth =====>>>> 0.9824999999999999 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 13 max_depth =====>>>> 0.981 \n",
            "Cross-Validation with 180 n_estimators Mean_score with 14 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 1 max_depth =====>>>> 0.8685 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 2 max_depth =====>>>> 0.9325000000000001 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 3 max_depth =====>>>> 0.9544999999999999 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 4 max_depth =====>>>> 0.966 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 5 max_depth =====>>>> 0.975 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 6 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 7 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 8 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 9 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 10 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 11 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 12 max_depth =====>>>> 0.9795 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 13 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 200 n_estimators Mean_score with 14 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 1 max_depth =====>>>> 0.8685 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 2 max_depth =====>>>> 0.9335 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 3 max_depth =====>>>> 0.9524999999999999 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 4 max_depth =====>>>> 0.966 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 5 max_depth =====>>>> 0.9735 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 6 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 7 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 8 max_depth =====>>>> 0.979 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 9 max_depth =====>>>> 0.9784999999999999 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 10 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 11 max_depth =====>>>> 0.981 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 12 max_depth =====>>>> 0.98 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 13 max_depth =====>>>> 0.978 \n",
            "Cross-Validation with 220 n_estimators Mean_score with 14 max_depth =====>>>> 0.9815 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrje4a2Af8vj",
        "colab_type": "text"
      },
      "source": [
        "**Лучший результат 80 estimators c max_depth = 10, протеестируем**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bor2vKbXf8Pj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2975f625-2a1a-48c8-fe65-eff2949fd7e8"
      },
      "source": [
        "RanFor = RandomForestClassifier(n_estimators=80, criterion='entropy', max_depth=10)\n",
        "RanFor.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = RanFor.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = RanFor.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.976\n",
            "ROC AUC: 0.995476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR0VBY_JxXx0",
        "colab_type": "text"
      },
      "source": [
        "###**Дополнительно**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Zw8IZ57ylK",
        "colab_type": "text"
      },
      "source": [
        "проанализировать feature_importances после применения классификатора."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL6c9j2hi8Uh",
        "colab_type": "text"
      },
      "source": [
        "**Выберем топ-5 признаков-пикселей которые имееют наибольшее влияние**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgvnkR2txYvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "2ba33567-f9a0-41a3-85f0-5ecda589bfe1"
      },
      "source": [
        "feat_importances = pd.Series(RanFor.feature_importances_, index=testQ.columns)\n",
        "feat_importances.nlargest(5).plot(kind='barh')"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1f721efd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 310
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIMG6FY7KCOo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57HBU6MZKAUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ff96fc9d-a6d6-4f68-b32d-b2fe7d86da56"
      },
      "source": [
        "a = np.zeros((28,28))\n",
        "a"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rHJd32uGId2",
        "colab_type": "text"
      },
      "source": [
        "##**AdaBoost SkLearn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzBdicEtGO5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgYRLnDQV-hr",
        "colab_type": "text"
      },
      "source": [
        "**max depth=9 как лучший результат для дерева решений**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE2mby6SiAeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6c473594-6e67-4810-98ad-5252dde67736"
      },
      "source": [
        "AdaBoo = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9), n_estimators=100)\n",
        "AdaBoo.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = AdaBoo.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = AdaBoo.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.975\n",
            "ROC AUC: 0.995817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxCGf05kipdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25072772-fcfc-40c0-80de-571cfdbb0c96"
      },
      "source": [
        "AdaBoo = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=100)\n",
        "RanFor.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = RanFor.predict(test_dataQ[:, 0:784])\n",
        "y_test = test_dataQ[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BLLIetwirJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17932d51-f036-4bd9-f8ee-035bb475aacd"
      },
      "source": [
        "AdaBoo = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=100)\n",
        "RanFor.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = RanFor.predict(test_dataO[:, 0:784])\n",
        "y_test = test_dataO[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl6WeHZ7lsIs",
        "colab_type": "text"
      },
      "source": [
        "###**Подбор параметров**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvlUhsylr15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "fd579295-f2d4-4e28-c2b8-8ae123b01c30"
      },
      "source": [
        "for i in range(50,100,10):\n",
        "  for j in range(2, 10,2):\n",
        "    AdaBoo = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9), n_estimators=i)\n",
        "    AdaB = cross_val_score(AdaBoo, train_datasetQO[:, 0:784], train_datasetQO[:, -1], cv=j)\n",
        "    print(\"Cross-Validation with {} n_estimators Mean_score with {}-fold cv =====>>>> {} \".format(i, j, str(AdaB.mean())))"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation with 50 n_estimators Mean_score with 2-fold cv =====>>>> 0.9405 \n",
            "Cross-Validation with 50 n_estimators Mean_score with 4-fold cv =====>>>> 0.981 \n",
            "Cross-Validation with 50 n_estimators Mean_score with 6-fold cv =====>>>> 0.9790208739148211 \n",
            "Cross-Validation with 50 n_estimators Mean_score with 8-fold cv =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 2-fold cv =====>>>> 0.9455 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 4-fold cv =====>>>> 0.9804999999999999 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 6-fold cv =====>>>> 0.9800008416901137 \n",
            "Cross-Validation with 60 n_estimators Mean_score with 8-fold cv =====>>>> 0.982 \n",
            "Cross-Validation with 70 n_estimators Mean_score with 2-fold cv =====>>>> 0.9455 \n",
            "Cross-Validation with 70 n_estimators Mean_score with 4-fold cv =====>>>> 0.978 \n",
            "Cross-Validation with 70 n_estimators Mean_score with 6-fold cv =====>>>> 0.9810198879349734 \n",
            "Cross-Validation with 70 n_estimators Mean_score with 8-fold cv =====>>>> 0.984 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 2-fold cv =====>>>> 0.9385 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 4-fold cv =====>>>> 0.98 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 6-fold cv =====>>>> 0.9845159079431499 \n",
            "Cross-Validation with 80 n_estimators Mean_score with 8-fold cv =====>>>> 0.9815 \n",
            "Cross-Validation with 90 n_estimators Mean_score with 2-fold cv =====>>>> 0.9455 \n",
            "Cross-Validation with 90 n_estimators Mean_score with 4-fold cv =====>>>> 0.98 \n",
            "Cross-Validation with 90 n_estimators Mean_score with 6-fold cv =====>>>> 0.981521895967102 \n",
            "Cross-Validation with 90 n_estimators Mean_score with 8-fold cv =====>>>> 0.9804999999999999 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87IbH3Nex8Ty",
        "colab_type": "text"
      },
      "source": [
        "**Лучшая точность у 80 n_estimators**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm7Wq_bstvYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "53f5b9e1-1784-4c53-c5d9-78116a31e994"
      },
      "source": [
        "AdaBoo = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9), n_estimators=80)\n",
        "AdaBoo.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])\n",
        "y_pred = AdaBoo.predict(test_datasetQO[:, 0:784])\n",
        "y_test = test_datasetQO[:, -1]\n",
        "y_proba = AdaBoo.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9735\n",
            "ROC AUC: 0.995654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jxK5d1XxZwC",
        "colab_type": "text"
      },
      "source": [
        "###**Дополнительно**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txW8SbLu753x",
        "colab_type": "text"
      },
      "source": [
        "взять XGBoost, CatBoost или LightGBM библиотеку, сравнить результаты с SkLearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GThcqWqJLS3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hxUkCPTxbAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from catboost import CatBoostClassifier #КОТИКИ!!!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ddn2OaL2Qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CatBoostClassifier(iterations=100,depth=21, learning_rate=1, loss_function='Logloss', verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpXuAYWVz-t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CatBoostClassifier(iterations=500,depth=9, learning_rate=1, loss_function='Logloss', verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxF3jcLZ2Shq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fe60ac5-b485-4731-e31f-8c40377a0a0a"
      },
      "source": [
        "model.fit(train_datasetQO[:, 0:784], train_datasetQO[:, -1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.1536983\ttotal: 1.18s\tremaining: 9m 48s\n",
            "1:\tlearn: 0.0774813\ttotal: 2.09s\tremaining: 8m 40s\n",
            "2:\tlearn: 0.0439826\ttotal: 3.02s\tremaining: 8m 20s\n",
            "3:\tlearn: 0.0280266\ttotal: 3.95s\tremaining: 8m 10s\n",
            "4:\tlearn: 0.0187360\ttotal: 4.87s\tremaining: 8m 1s\n",
            "5:\tlearn: 0.0136132\ttotal: 5.78s\tremaining: 7m 56s\n",
            "6:\tlearn: 0.0105994\ttotal: 6.73s\tremaining: 7m 54s\n",
            "7:\tlearn: 0.0091486\ttotal: 7.65s\tremaining: 7m 50s\n",
            "8:\tlearn: 0.0072486\ttotal: 8.57s\tremaining: 7m 47s\n",
            "9:\tlearn: 0.0060236\ttotal: 9.49s\tremaining: 7m 45s\n",
            "10:\tlearn: 0.0056833\ttotal: 10.4s\tremaining: 7m 43s\n",
            "11:\tlearn: 0.0048955\ttotal: 11.3s\tremaining: 7m 40s\n",
            "12:\tlearn: 0.0047580\ttotal: 12.2s\tremaining: 7m 38s\n",
            "13:\tlearn: 0.0043890\ttotal: 13.1s\tremaining: 7m 36s\n",
            "14:\tlearn: 0.0037541\ttotal: 14.1s\tremaining: 7m 34s\n",
            "15:\tlearn: 0.0032845\ttotal: 15s\tremaining: 7m 32s\n",
            "16:\tlearn: 0.0030175\ttotal: 15.9s\tremaining: 7m 30s\n",
            "17:\tlearn: 0.0027479\ttotal: 16.8s\tremaining: 7m 30s\n",
            "18:\tlearn: 0.0025542\ttotal: 17.7s\tremaining: 7m 28s\n",
            "19:\tlearn: 0.0022982\ttotal: 18.6s\tremaining: 7m 26s\n",
            "20:\tlearn: 0.0020605\ttotal: 19.5s\tremaining: 7m 25s\n",
            "21:\tlearn: 0.0018920\ttotal: 20.4s\tremaining: 7m 23s\n",
            "22:\tlearn: 0.0017357\ttotal: 21.3s\tremaining: 7m 22s\n",
            "23:\tlearn: 0.0016225\ttotal: 22.2s\tremaining: 7m 21s\n",
            "24:\tlearn: 0.0015413\ttotal: 23.2s\tremaining: 7m 20s\n",
            "25:\tlearn: 0.0014622\ttotal: 24.1s\tremaining: 7m 19s\n",
            "26:\tlearn: 0.0013642\ttotal: 25s\tremaining: 7m 17s\n",
            "27:\tlearn: 0.0012959\ttotal: 25.9s\tremaining: 7m 16s\n",
            "28:\tlearn: 0.0012282\ttotal: 26.8s\tremaining: 7m 15s\n",
            "29:\tlearn: 0.0011954\ttotal: 27.7s\tremaining: 7m 14s\n",
            "30:\tlearn: 0.0011446\ttotal: 28.6s\tremaining: 7m 13s\n",
            "31:\tlearn: 0.0011248\ttotal: 29.5s\tremaining: 7m 11s\n",
            "32:\tlearn: 0.0010749\ttotal: 30.4s\tremaining: 7m 10s\n",
            "33:\tlearn: 0.0010437\ttotal: 31.3s\tremaining: 7m 9s\n",
            "34:\tlearn: 0.0010271\ttotal: 32.2s\tremaining: 7m 8s\n",
            "35:\tlearn: 0.0009993\ttotal: 33.1s\tremaining: 7m 7s\n",
            "36:\tlearn: 0.0009515\ttotal: 34.1s\tremaining: 7m 6s\n",
            "37:\tlearn: 0.0009072\ttotal: 34.9s\tremaining: 7m 4s\n",
            "38:\tlearn: 0.0008971\ttotal: 35.9s\tremaining: 7m 3s\n",
            "39:\tlearn: 0.0008809\ttotal: 36.8s\tremaining: 7m 2s\n",
            "40:\tlearn: 0.0008544\ttotal: 37.7s\tremaining: 7m 1s\n",
            "41:\tlearn: 0.0008257\ttotal: 38.6s\tremaining: 7m\n",
            "42:\tlearn: 0.0008020\ttotal: 39.5s\tremaining: 6m 59s\n",
            "43:\tlearn: 0.0007805\ttotal: 40.4s\tremaining: 6m 58s\n",
            "44:\tlearn: 0.0007618\ttotal: 41.3s\tremaining: 6m 57s\n",
            "45:\tlearn: 0.0007492\ttotal: 42.2s\tremaining: 6m 56s\n",
            "46:\tlearn: 0.0007192\ttotal: 43.1s\tremaining: 6m 55s\n",
            "47:\tlearn: 0.0007065\ttotal: 44s\tremaining: 6m 54s\n",
            "48:\tlearn: 0.0006952\ttotal: 44.9s\tremaining: 6m 53s\n",
            "49:\tlearn: 0.0006798\ttotal: 45.8s\tremaining: 6m 52s\n",
            "50:\tlearn: 0.0006729\ttotal: 46.7s\tremaining: 6m 51s\n",
            "51:\tlearn: 0.0006505\ttotal: 47.7s\tremaining: 6m 50s\n",
            "52:\tlearn: 0.0006397\ttotal: 48.6s\tremaining: 6m 49s\n",
            "53:\tlearn: 0.0006263\ttotal: 49.5s\tremaining: 6m 48s\n",
            "54:\tlearn: 0.0006169\ttotal: 50.4s\tremaining: 6m 47s\n",
            "55:\tlearn: 0.0006006\ttotal: 51.3s\tremaining: 6m 46s\n",
            "56:\tlearn: 0.0005854\ttotal: 52.2s\tremaining: 6m 45s\n",
            "57:\tlearn: 0.0005771\ttotal: 53.1s\tremaining: 6m 44s\n",
            "58:\tlearn: 0.0005476\ttotal: 54s\tremaining: 6m 43s\n",
            "59:\tlearn: 0.0005411\ttotal: 54.9s\tremaining: 6m 42s\n",
            "60:\tlearn: 0.0005339\ttotal: 55.8s\tremaining: 6m 41s\n",
            "61:\tlearn: 0.0005288\ttotal: 56.7s\tremaining: 6m 40s\n",
            "62:\tlearn: 0.0005179\ttotal: 57.6s\tremaining: 6m 39s\n",
            "63:\tlearn: 0.0005029\ttotal: 58.6s\tremaining: 6m 39s\n",
            "64:\tlearn: 0.0004903\ttotal: 59.5s\tremaining: 6m 37s\n",
            "65:\tlearn: 0.0004875\ttotal: 1m\tremaining: 6m 36s\n",
            "66:\tlearn: 0.0004797\ttotal: 1m 1s\tremaining: 6m 36s\n",
            "67:\tlearn: 0.0004642\ttotal: 1m 2s\tremaining: 6m 35s\n",
            "68:\tlearn: 0.0004566\ttotal: 1m 3s\tremaining: 6m 34s\n",
            "69:\tlearn: 0.0004477\ttotal: 1m 4s\tremaining: 6m 33s\n",
            "70:\tlearn: 0.0004358\ttotal: 1m 4s\tremaining: 6m 32s\n",
            "71:\tlearn: 0.0004294\ttotal: 1m 5s\tremaining: 6m 31s\n",
            "72:\tlearn: 0.0004160\ttotal: 1m 6s\tremaining: 6m 30s\n",
            "73:\tlearn: 0.0004095\ttotal: 1m 7s\tremaining: 6m 29s\n",
            "74:\tlearn: 0.0004054\ttotal: 1m 8s\tremaining: 6m 28s\n",
            "75:\tlearn: 0.0004012\ttotal: 1m 9s\tremaining: 6m 27s\n",
            "76:\tlearn: 0.0003983\ttotal: 1m 10s\tremaining: 6m 26s\n",
            "77:\tlearn: 0.0003903\ttotal: 1m 11s\tremaining: 6m 25s\n",
            "78:\tlearn: 0.0003824\ttotal: 1m 12s\tremaining: 6m 24s\n",
            "79:\tlearn: 0.0003751\ttotal: 1m 13s\tremaining: 6m 23s\n",
            "80:\tlearn: 0.0003714\ttotal: 1m 14s\tremaining: 6m 22s\n",
            "81:\tlearn: 0.0003685\ttotal: 1m 14s\tremaining: 6m 21s\n",
            "82:\tlearn: 0.0003620\ttotal: 1m 15s\tremaining: 6m 20s\n",
            "83:\tlearn: 0.0003562\ttotal: 1m 16s\tremaining: 6m 19s\n",
            "84:\tlearn: 0.0003528\ttotal: 1m 17s\tremaining: 6m 19s\n",
            "85:\tlearn: 0.0003511\ttotal: 1m 18s\tremaining: 6m 18s\n",
            "86:\tlearn: 0.0003487\ttotal: 1m 19s\tremaining: 6m 17s\n",
            "87:\tlearn: 0.0003463\ttotal: 1m 20s\tremaining: 6m 16s\n",
            "88:\tlearn: 0.0003381\ttotal: 1m 21s\tremaining: 6m 15s\n",
            "89:\tlearn: 0.0003364\ttotal: 1m 22s\tremaining: 6m 14s\n",
            "90:\tlearn: 0.0003317\ttotal: 1m 23s\tremaining: 6m 13s\n",
            "91:\tlearn: 0.0003254\ttotal: 1m 24s\tremaining: 6m 12s\n",
            "92:\tlearn: 0.0003151\ttotal: 1m 24s\tremaining: 6m 11s\n",
            "93:\tlearn: 0.0003125\ttotal: 1m 25s\tremaining: 6m 10s\n",
            "94:\tlearn: 0.0003103\ttotal: 1m 26s\tremaining: 6m 9s\n",
            "95:\tlearn: 0.0003080\ttotal: 1m 27s\tremaining: 6m 8s\n",
            "96:\tlearn: 0.0003051\ttotal: 1m 28s\tremaining: 6m 8s\n",
            "97:\tlearn: 0.0003039\ttotal: 1m 29s\tremaining: 6m 7s\n",
            "98:\tlearn: 0.0003017\ttotal: 1m 30s\tremaining: 6m 6s\n",
            "99:\tlearn: 0.0002983\ttotal: 1m 31s\tremaining: 6m 6s\n",
            "100:\tlearn: 0.0002941\ttotal: 1m 32s\tremaining: 6m 5s\n",
            "101:\tlearn: 0.0002925\ttotal: 1m 33s\tremaining: 6m 4s\n",
            "102:\tlearn: 0.0002906\ttotal: 1m 34s\tremaining: 6m 3s\n",
            "103:\tlearn: 0.0002891\ttotal: 1m 35s\tremaining: 6m 2s\n",
            "104:\tlearn: 0.0002877\ttotal: 1m 36s\tremaining: 6m 1s\n",
            "105:\tlearn: 0.0002851\ttotal: 1m 36s\tremaining: 6m\n",
            "106:\tlearn: 0.0002812\ttotal: 1m 37s\tremaining: 5m 59s\n",
            "107:\tlearn: 0.0002757\ttotal: 1m 38s\tremaining: 5m 58s\n",
            "108:\tlearn: 0.0002732\ttotal: 1m 39s\tremaining: 5m 57s\n",
            "109:\tlearn: 0.0002723\ttotal: 1m 40s\tremaining: 5m 56s\n",
            "110:\tlearn: 0.0002695\ttotal: 1m 41s\tremaining: 5m 55s\n",
            "111:\tlearn: 0.0002674\ttotal: 1m 42s\tremaining: 5m 54s\n",
            "112:\tlearn: 0.0002631\ttotal: 1m 43s\tremaining: 5m 53s\n",
            "113:\tlearn: 0.0002602\ttotal: 1m 44s\tremaining: 5m 52s\n",
            "114:\tlearn: 0.0002574\ttotal: 1m 45s\tremaining: 5m 51s\n",
            "115:\tlearn: 0.0002558\ttotal: 1m 46s\tremaining: 5m 50s\n",
            "116:\tlearn: 0.0002524\ttotal: 1m 46s\tremaining: 5m 49s\n",
            "117:\tlearn: 0.0002514\ttotal: 1m 47s\tremaining: 5m 49s\n",
            "118:\tlearn: 0.0002505\ttotal: 1m 48s\tremaining: 5m 48s\n",
            "119:\tlearn: 0.0002491\ttotal: 1m 49s\tremaining: 5m 47s\n",
            "120:\tlearn: 0.0002481\ttotal: 1m 50s\tremaining: 5m 46s\n",
            "121:\tlearn: 0.0002462\ttotal: 1m 51s\tremaining: 5m 45s\n",
            "122:\tlearn: 0.0002453\ttotal: 1m 52s\tremaining: 5m 44s\n",
            "123:\tlearn: 0.0002428\ttotal: 1m 53s\tremaining: 5m 43s\n",
            "124:\tlearn: 0.0002422\ttotal: 1m 54s\tremaining: 5m 42s\n",
            "125:\tlearn: 0.0002394\ttotal: 1m 55s\tremaining: 5m 41s\n",
            "126:\tlearn: 0.0002331\ttotal: 1m 56s\tremaining: 5m 40s\n",
            "127:\tlearn: 0.0002326\ttotal: 1m 56s\tremaining: 5m 39s\n",
            "128:\tlearn: 0.0002309\ttotal: 1m 57s\tremaining: 5m 38s\n",
            "129:\tlearn: 0.0002291\ttotal: 1m 58s\tremaining: 5m 38s\n",
            "130:\tlearn: 0.0002279\ttotal: 1m 59s\tremaining: 5m 37s\n",
            "131:\tlearn: 0.0002262\ttotal: 2m\tremaining: 5m 36s\n",
            "132:\tlearn: 0.0002226\ttotal: 2m 1s\tremaining: 5m 35s\n",
            "133:\tlearn: 0.0002187\ttotal: 2m 2s\tremaining: 5m 34s\n",
            "134:\tlearn: 0.0002166\ttotal: 2m 3s\tremaining: 5m 33s\n",
            "135:\tlearn: 0.0002148\ttotal: 2m 4s\tremaining: 5m 32s\n",
            "136:\tlearn: 0.0002131\ttotal: 2m 5s\tremaining: 5m 31s\n",
            "137:\tlearn: 0.0002117\ttotal: 2m 6s\tremaining: 5m 30s\n",
            "138:\tlearn: 0.0002105\ttotal: 2m 6s\tremaining: 5m 29s\n",
            "139:\tlearn: 0.0002085\ttotal: 2m 7s\tremaining: 5m 28s\n",
            "140:\tlearn: 0.0002076\ttotal: 2m 8s\tremaining: 5m 27s\n",
            "141:\tlearn: 0.0002063\ttotal: 2m 9s\tremaining: 5m 26s\n",
            "142:\tlearn: 0.0002050\ttotal: 2m 10s\tremaining: 5m 26s\n",
            "143:\tlearn: 0.0002035\ttotal: 2m 11s\tremaining: 5m 25s\n",
            "144:\tlearn: 0.0002019\ttotal: 2m 12s\tremaining: 5m 24s\n",
            "145:\tlearn: 0.0002001\ttotal: 2m 13s\tremaining: 5m 23s\n",
            "146:\tlearn: 0.0001980\ttotal: 2m 14s\tremaining: 5m 22s\n",
            "147:\tlearn: 0.0001972\ttotal: 2m 15s\tremaining: 5m 21s\n",
            "148:\tlearn: 0.0001955\ttotal: 2m 16s\tremaining: 5m 20s\n",
            "149:\tlearn: 0.0001944\ttotal: 2m 16s\tremaining: 5m 19s\n",
            "150:\tlearn: 0.0001930\ttotal: 2m 17s\tremaining: 5m 18s\n",
            "151:\tlearn: 0.0001908\ttotal: 2m 18s\tremaining: 5m 17s\n",
            "152:\tlearn: 0.0001898\ttotal: 2m 19s\tremaining: 5m 16s\n",
            "153:\tlearn: 0.0001895\ttotal: 2m 20s\tremaining: 5m 15s\n",
            "154:\tlearn: 0.0001887\ttotal: 2m 21s\tremaining: 5m 15s\n",
            "155:\tlearn: 0.0001870\ttotal: 2m 22s\tremaining: 5m 14s\n",
            "156:\tlearn: 0.0001862\ttotal: 2m 23s\tremaining: 5m 13s\n",
            "157:\tlearn: 0.0001859\ttotal: 2m 24s\tremaining: 5m 12s\n",
            "158:\tlearn: 0.0001847\ttotal: 2m 25s\tremaining: 5m 11s\n",
            "159:\tlearn: 0.0001834\ttotal: 2m 26s\tremaining: 5m 10s\n",
            "160:\tlearn: 0.0001824\ttotal: 2m 27s\tremaining: 5m 9s\n",
            "161:\tlearn: 0.0001810\ttotal: 2m 27s\tremaining: 5m 8s\n",
            "162:\tlearn: 0.0001797\ttotal: 2m 28s\tremaining: 5m 7s\n",
            "163:\tlearn: 0.0001786\ttotal: 2m 29s\tremaining: 5m 6s\n",
            "164:\tlearn: 0.0001767\ttotal: 2m 30s\tremaining: 5m 6s\n",
            "165:\tlearn: 0.0001754\ttotal: 2m 31s\tremaining: 5m 5s\n",
            "166:\tlearn: 0.0001726\ttotal: 2m 32s\tremaining: 5m 4s\n",
            "167:\tlearn: 0.0001714\ttotal: 2m 33s\tremaining: 5m 3s\n",
            "168:\tlearn: 0.0001706\ttotal: 2m 34s\tremaining: 5m 2s\n",
            "169:\tlearn: 0.0001690\ttotal: 2m 35s\tremaining: 5m 1s\n",
            "170:\tlearn: 0.0001684\ttotal: 2m 36s\tremaining: 5m\n",
            "171:\tlearn: 0.0001673\ttotal: 2m 37s\tremaining: 4m 59s\n",
            "172:\tlearn: 0.0001669\ttotal: 2m 38s\tremaining: 4m 58s\n",
            "173:\tlearn: 0.0001669\ttotal: 2m 39s\tremaining: 4m 57s\n",
            "174:\tlearn: 0.0001653\ttotal: 2m 39s\tremaining: 4m 57s\n",
            "175:\tlearn: 0.0001642\ttotal: 2m 40s\tremaining: 4m 56s\n",
            "176:\tlearn: 0.0001637\ttotal: 2m 41s\tremaining: 4m 55s\n",
            "177:\tlearn: 0.0001627\ttotal: 2m 42s\tremaining: 4m 54s\n",
            "178:\tlearn: 0.0001612\ttotal: 2m 43s\tremaining: 4m 53s\n",
            "179:\tlearn: 0.0001602\ttotal: 2m 44s\tremaining: 4m 52s\n",
            "180:\tlearn: 0.0001594\ttotal: 2m 45s\tremaining: 4m 52s\n",
            "181:\tlearn: 0.0001585\ttotal: 2m 46s\tremaining: 4m 51s\n",
            "182:\tlearn: 0.0001579\ttotal: 2m 47s\tremaining: 4m 50s\n",
            "183:\tlearn: 0.0001570\ttotal: 2m 48s\tremaining: 4m 49s\n",
            "184:\tlearn: 0.0001565\ttotal: 2m 49s\tremaining: 4m 48s\n",
            "185:\tlearn: 0.0001557\ttotal: 2m 50s\tremaining: 4m 47s\n",
            "186:\tlearn: 0.0001551\ttotal: 2m 51s\tremaining: 4m 46s\n",
            "187:\tlearn: 0.0001545\ttotal: 2m 52s\tremaining: 4m 45s\n",
            "188:\tlearn: 0.0001533\ttotal: 2m 53s\tremaining: 4m 44s\n",
            "189:\tlearn: 0.0001525\ttotal: 2m 54s\tremaining: 4m 43s\n",
            "190:\tlearn: 0.0001525\ttotal: 2m 54s\tremaining: 4m 42s\n",
            "191:\tlearn: 0.0001518\ttotal: 2m 55s\tremaining: 4m 42s\n",
            "192:\tlearn: 0.0001513\ttotal: 2m 56s\tremaining: 4m 41s\n",
            "193:\tlearn: 0.0001504\ttotal: 2m 57s\tremaining: 4m 40s\n",
            "194:\tlearn: 0.0001497\ttotal: 2m 58s\tremaining: 4m 39s\n",
            "195:\tlearn: 0.0001489\ttotal: 2m 59s\tremaining: 4m 38s\n",
            "196:\tlearn: 0.0001479\ttotal: 3m\tremaining: 4m 37s\n",
            "197:\tlearn: 0.0001469\ttotal: 3m 1s\tremaining: 4m 36s\n",
            "198:\tlearn: 0.0001465\ttotal: 3m 2s\tremaining: 4m 35s\n",
            "199:\tlearn: 0.0001451\ttotal: 3m 3s\tremaining: 4m 34s\n",
            "200:\tlearn: 0.0001450\ttotal: 3m 4s\tremaining: 4m 33s\n",
            "201:\tlearn: 0.0001450\ttotal: 3m 4s\tremaining: 4m 32s\n",
            "202:\tlearn: 0.0001443\ttotal: 3m 5s\tremaining: 4m 31s\n",
            "203:\tlearn: 0.0001441\ttotal: 3m 6s\tremaining: 4m 31s\n",
            "204:\tlearn: 0.0001441\ttotal: 3m 7s\tremaining: 4m 30s\n",
            "205:\tlearn: 0.0001436\ttotal: 3m 8s\tremaining: 4m 29s\n",
            "206:\tlearn: 0.0001431\ttotal: 3m 9s\tremaining: 4m 28s\n",
            "207:\tlearn: 0.0001423\ttotal: 3m 10s\tremaining: 4m 27s\n",
            "208:\tlearn: 0.0001420\ttotal: 3m 11s\tremaining: 4m 26s\n",
            "209:\tlearn: 0.0001409\ttotal: 3m 12s\tremaining: 4m 25s\n",
            "210:\tlearn: 0.0001409\ttotal: 3m 13s\tremaining: 4m 24s\n",
            "211:\tlearn: 0.0001407\ttotal: 3m 14s\tremaining: 4m 23s\n",
            "212:\tlearn: 0.0001405\ttotal: 3m 14s\tremaining: 4m 22s\n",
            "213:\tlearn: 0.0001405\ttotal: 3m 15s\tremaining: 4m 21s\n",
            "214:\tlearn: 0.0001401\ttotal: 3m 16s\tremaining: 4m 20s\n",
            "215:\tlearn: 0.0001391\ttotal: 3m 17s\tremaining: 4m 20s\n",
            "216:\tlearn: 0.0001388\ttotal: 3m 18s\tremaining: 4m 19s\n",
            "217:\tlearn: 0.0001378\ttotal: 3m 19s\tremaining: 4m 18s\n",
            "218:\tlearn: 0.0001375\ttotal: 3m 20s\tremaining: 4m 17s\n",
            "219:\tlearn: 0.0001375\ttotal: 3m 21s\tremaining: 4m 16s\n",
            "220:\tlearn: 0.0001375\ttotal: 3m 22s\tremaining: 4m 15s\n",
            "221:\tlearn: 0.0001374\ttotal: 3m 23s\tremaining: 4m 14s\n",
            "222:\tlearn: 0.0001369\ttotal: 3m 24s\tremaining: 4m 13s\n",
            "223:\tlearn: 0.0001365\ttotal: 3m 25s\tremaining: 4m 12s\n",
            "224:\tlearn: 0.0001365\ttotal: 3m 26s\tremaining: 4m 11s\n",
            "225:\tlearn: 0.0001365\ttotal: 3m 27s\tremaining: 4m 10s\n",
            "226:\tlearn: 0.0001358\ttotal: 3m 27s\tremaining: 4m 10s\n",
            "227:\tlearn: 0.0001351\ttotal: 3m 28s\tremaining: 4m 9s\n",
            "228:\tlearn: 0.0001350\ttotal: 3m 29s\tremaining: 4m 8s\n",
            "229:\tlearn: 0.0001350\ttotal: 3m 30s\tremaining: 4m 7s\n",
            "230:\tlearn: 0.0001350\ttotal: 3m 31s\tremaining: 4m 6s\n",
            "231:\tlearn: 0.0001344\ttotal: 3m 32s\tremaining: 4m 5s\n",
            "232:\tlearn: 0.0001341\ttotal: 3m 33s\tremaining: 4m 4s\n",
            "233:\tlearn: 0.0001338\ttotal: 3m 34s\tremaining: 4m 3s\n",
            "234:\tlearn: 0.0001335\ttotal: 3m 35s\tremaining: 4m 2s\n",
            "235:\tlearn: 0.0001328\ttotal: 3m 36s\tremaining: 4m 1s\n",
            "236:\tlearn: 0.0001328\ttotal: 3m 37s\tremaining: 4m 1s\n",
            "237:\tlearn: 0.0001314\ttotal: 3m 38s\tremaining: 4m\n",
            "238:\tlearn: 0.0001313\ttotal: 3m 39s\tremaining: 3m 59s\n",
            "239:\tlearn: 0.0001311\ttotal: 3m 39s\tremaining: 3m 58s\n",
            "240:\tlearn: 0.0001298\ttotal: 3m 40s\tremaining: 3m 57s\n",
            "241:\tlearn: 0.0001298\ttotal: 3m 41s\tremaining: 3m 56s\n",
            "242:\tlearn: 0.0001296\ttotal: 3m 42s\tremaining: 3m 55s\n",
            "243:\tlearn: 0.0001296\ttotal: 3m 43s\tremaining: 3m 54s\n",
            "244:\tlearn: 0.0001296\ttotal: 3m 44s\tremaining: 3m 53s\n",
            "245:\tlearn: 0.0001296\ttotal: 3m 45s\tremaining: 3m 52s\n",
            "246:\tlearn: 0.0001296\ttotal: 3m 46s\tremaining: 3m 51s\n",
            "247:\tlearn: 0.0001296\ttotal: 3m 47s\tremaining: 3m 50s\n",
            "248:\tlearn: 0.0001296\ttotal: 3m 48s\tremaining: 3m 50s\n",
            "249:\tlearn: 0.0001296\ttotal: 3m 49s\tremaining: 3m 49s\n",
            "250:\tlearn: 0.0001296\ttotal: 3m 50s\tremaining: 3m 48s\n",
            "251:\tlearn: 0.0001296\ttotal: 3m 50s\tremaining: 3m 47s\n",
            "252:\tlearn: 0.0001296\ttotal: 3m 51s\tremaining: 3m 46s\n",
            "253:\tlearn: 0.0001296\ttotal: 3m 52s\tremaining: 3m 45s\n",
            "254:\tlearn: 0.0001296\ttotal: 3m 53s\tremaining: 3m 44s\n",
            "255:\tlearn: 0.0001296\ttotal: 3m 54s\tremaining: 3m 43s\n",
            "256:\tlearn: 0.0001296\ttotal: 3m 55s\tremaining: 3m 42s\n",
            "257:\tlearn: 0.0001294\ttotal: 3m 56s\tremaining: 3m 41s\n",
            "258:\tlearn: 0.0001286\ttotal: 3m 57s\tremaining: 3m 40s\n",
            "259:\tlearn: 0.0001283\ttotal: 3m 58s\tremaining: 3m 39s\n",
            "260:\tlearn: 0.0001274\ttotal: 3m 59s\tremaining: 3m 39s\n",
            "261:\tlearn: 0.0001274\ttotal: 4m\tremaining: 3m 38s\n",
            "262:\tlearn: 0.0001260\ttotal: 4m\tremaining: 3m 37s\n",
            "263:\tlearn: 0.0001259\ttotal: 4m 1s\tremaining: 3m 36s\n",
            "264:\tlearn: 0.0001252\ttotal: 4m 2s\tremaining: 3m 35s\n",
            "265:\tlearn: 0.0001243\ttotal: 4m 3s\tremaining: 3m 34s\n",
            "266:\tlearn: 0.0001241\ttotal: 4m 4s\tremaining: 3m 33s\n",
            "267:\tlearn: 0.0001241\ttotal: 4m 5s\tremaining: 3m 32s\n",
            "268:\tlearn: 0.0001232\ttotal: 4m 6s\tremaining: 3m 31s\n",
            "269:\tlearn: 0.0001229\ttotal: 4m 7s\tremaining: 3m 30s\n",
            "270:\tlearn: 0.0001229\ttotal: 4m 8s\tremaining: 3m 29s\n",
            "271:\tlearn: 0.0001229\ttotal: 4m 9s\tremaining: 3m 28s\n",
            "272:\tlearn: 0.0001224\ttotal: 4m 10s\tremaining: 3m 27s\n",
            "273:\tlearn: 0.0001223\ttotal: 4m 10s\tremaining: 3m 27s\n",
            "274:\tlearn: 0.0001222\ttotal: 4m 11s\tremaining: 3m 26s\n",
            "275:\tlearn: 0.0001220\ttotal: 4m 12s\tremaining: 3m 25s\n",
            "276:\tlearn: 0.0001217\ttotal: 4m 13s\tremaining: 3m 24s\n",
            "277:\tlearn: 0.0001217\ttotal: 4m 14s\tremaining: 3m 23s\n",
            "278:\tlearn: 0.0001217\ttotal: 4m 15s\tremaining: 3m 22s\n",
            "279:\tlearn: 0.0001217\ttotal: 4m 16s\tremaining: 3m 21s\n",
            "280:\tlearn: 0.0001217\ttotal: 4m 17s\tremaining: 3m 20s\n",
            "281:\tlearn: 0.0001217\ttotal: 4m 18s\tremaining: 3m 19s\n",
            "282:\tlearn: 0.0001208\ttotal: 4m 19s\tremaining: 3m 18s\n",
            "283:\tlearn: 0.0001207\ttotal: 4m 20s\tremaining: 3m 17s\n",
            "284:\tlearn: 0.0001207\ttotal: 4m 20s\tremaining: 3m 16s\n",
            "285:\tlearn: 0.0001207\ttotal: 4m 21s\tremaining: 3m 15s\n",
            "286:\tlearn: 0.0001207\ttotal: 4m 22s\tremaining: 3m 15s\n",
            "287:\tlearn: 0.0001207\ttotal: 4m 23s\tremaining: 3m 14s\n",
            "288:\tlearn: 0.0001207\ttotal: 4m 24s\tremaining: 3m 13s\n",
            "289:\tlearn: 0.0001207\ttotal: 4m 25s\tremaining: 3m 12s\n",
            "290:\tlearn: 0.0001197\ttotal: 4m 26s\tremaining: 3m 11s\n",
            "291:\tlearn: 0.0001195\ttotal: 4m 27s\tremaining: 3m 10s\n",
            "292:\tlearn: 0.0001193\ttotal: 4m 28s\tremaining: 3m 9s\n",
            "293:\tlearn: 0.0001193\ttotal: 4m 29s\tremaining: 3m 8s\n",
            "294:\tlearn: 0.0001193\ttotal: 4m 30s\tremaining: 3m 7s\n",
            "295:\tlearn: 0.0001193\ttotal: 4m 30s\tremaining: 3m 6s\n",
            "296:\tlearn: 0.0001193\ttotal: 4m 31s\tremaining: 3m 5s\n",
            "297:\tlearn: 0.0001193\ttotal: 4m 32s\tremaining: 3m 4s\n",
            "298:\tlearn: 0.0001193\ttotal: 4m 33s\tremaining: 3m 3s\n",
            "299:\tlearn: 0.0001193\ttotal: 4m 34s\tremaining: 3m 3s\n",
            "300:\tlearn: 0.0001193\ttotal: 4m 35s\tremaining: 3m 2s\n",
            "301:\tlearn: 0.0001193\ttotal: 4m 36s\tremaining: 3m 1s\n",
            "302:\tlearn: 0.0001193\ttotal: 4m 37s\tremaining: 3m\n",
            "303:\tlearn: 0.0001193\ttotal: 4m 38s\tremaining: 2m 59s\n",
            "304:\tlearn: 0.0001193\ttotal: 4m 39s\tremaining: 2m 58s\n",
            "305:\tlearn: 0.0001193\ttotal: 4m 40s\tremaining: 2m 57s\n",
            "306:\tlearn: 0.0001193\ttotal: 4m 40s\tremaining: 2m 56s\n",
            "307:\tlearn: 0.0001193\ttotal: 4m 41s\tremaining: 2m 55s\n",
            "308:\tlearn: 0.0001193\ttotal: 4m 42s\tremaining: 2m 54s\n",
            "309:\tlearn: 0.0001193\ttotal: 4m 43s\tremaining: 2m 53s\n",
            "310:\tlearn: 0.0001193\ttotal: 4m 44s\tremaining: 2m 52s\n",
            "311:\tlearn: 0.0001193\ttotal: 4m 45s\tremaining: 2m 52s\n",
            "312:\tlearn: 0.0001193\ttotal: 4m 46s\tremaining: 2m 51s\n",
            "313:\tlearn: 0.0001193\ttotal: 4m 47s\tremaining: 2m 50s\n",
            "314:\tlearn: 0.0001193\ttotal: 4m 48s\tremaining: 2m 49s\n",
            "315:\tlearn: 0.0001193\ttotal: 4m 49s\tremaining: 2m 48s\n",
            "316:\tlearn: 0.0001193\ttotal: 4m 50s\tremaining: 2m 47s\n",
            "317:\tlearn: 0.0001193\ttotal: 4m 50s\tremaining: 2m 46s\n",
            "318:\tlearn: 0.0001193\ttotal: 4m 51s\tremaining: 2m 45s\n",
            "319:\tlearn: 0.0001193\ttotal: 4m 52s\tremaining: 2m 44s\n",
            "320:\tlearn: 0.0001193\ttotal: 4m 53s\tremaining: 2m 43s\n",
            "321:\tlearn: 0.0001193\ttotal: 4m 54s\tremaining: 2m 42s\n",
            "322:\tlearn: 0.0001193\ttotal: 4m 55s\tremaining: 2m 41s\n",
            "323:\tlearn: 0.0001193\ttotal: 4m 56s\tremaining: 2m 41s\n",
            "324:\tlearn: 0.0001193\ttotal: 4m 57s\tremaining: 2m 40s\n",
            "325:\tlearn: 0.0001193\ttotal: 4m 58s\tremaining: 2m 39s\n",
            "326:\tlearn: 0.0001193\ttotal: 4m 59s\tremaining: 2m 38s\n",
            "327:\tlearn: 0.0001193\ttotal: 5m\tremaining: 2m 37s\n",
            "328:\tlearn: 0.0001193\ttotal: 5m\tremaining: 2m 36s\n",
            "329:\tlearn: 0.0001193\ttotal: 5m 1s\tremaining: 2m 35s\n",
            "330:\tlearn: 0.0001193\ttotal: 5m 2s\tremaining: 2m 34s\n",
            "331:\tlearn: 0.0001193\ttotal: 5m 3s\tremaining: 2m 33s\n",
            "332:\tlearn: 0.0001193\ttotal: 5m 4s\tremaining: 2m 32s\n",
            "333:\tlearn: 0.0001193\ttotal: 5m 5s\tremaining: 2m 31s\n",
            "334:\tlearn: 0.0001193\ttotal: 5m 6s\tremaining: 2m 30s\n",
            "335:\tlearn: 0.0001193\ttotal: 5m 7s\tremaining: 2m 30s\n",
            "336:\tlearn: 0.0001193\ttotal: 5m 8s\tremaining: 2m 29s\n",
            "337:\tlearn: 0.0001193\ttotal: 5m 9s\tremaining: 2m 28s\n",
            "338:\tlearn: 0.0001193\ttotal: 5m 10s\tremaining: 2m 27s\n",
            "339:\tlearn: 0.0001193\ttotal: 5m 11s\tremaining: 2m 26s\n",
            "340:\tlearn: 0.0001193\ttotal: 5m 11s\tremaining: 2m 25s\n",
            "341:\tlearn: 0.0001193\ttotal: 5m 12s\tremaining: 2m 24s\n",
            "342:\tlearn: 0.0001193\ttotal: 5m 13s\tremaining: 2m 23s\n",
            "343:\tlearn: 0.0001193\ttotal: 5m 14s\tremaining: 2m 22s\n",
            "344:\tlearn: 0.0001193\ttotal: 5m 15s\tremaining: 2m 21s\n",
            "345:\tlearn: 0.0001193\ttotal: 5m 16s\tremaining: 2m 20s\n",
            "346:\tlearn: 0.0001193\ttotal: 5m 17s\tremaining: 2m 19s\n",
            "347:\tlearn: 0.0001192\ttotal: 5m 18s\tremaining: 2m 19s\n",
            "348:\tlearn: 0.0001192\ttotal: 5m 19s\tremaining: 2m 18s\n",
            "349:\tlearn: 0.0001192\ttotal: 5m 20s\tremaining: 2m 17s\n",
            "350:\tlearn: 0.0001192\ttotal: 5m 21s\tremaining: 2m 16s\n",
            "351:\tlearn: 0.0001192\ttotal: 5m 22s\tremaining: 2m 15s\n",
            "352:\tlearn: 0.0001192\ttotal: 5m 22s\tremaining: 2m 14s\n",
            "353:\tlearn: 0.0001192\ttotal: 5m 23s\tremaining: 2m 13s\n",
            "354:\tlearn: 0.0001192\ttotal: 5m 24s\tremaining: 2m 12s\n",
            "355:\tlearn: 0.0001192\ttotal: 5m 25s\tremaining: 2m 11s\n",
            "356:\tlearn: 0.0001192\ttotal: 5m 26s\tremaining: 2m 10s\n",
            "357:\tlearn: 0.0001184\ttotal: 5m 27s\tremaining: 2m 9s\n",
            "358:\tlearn: 0.0001180\ttotal: 5m 28s\tremaining: 2m 9s\n",
            "359:\tlearn: 0.0001180\ttotal: 5m 29s\tremaining: 2m 8s\n",
            "360:\tlearn: 0.0001180\ttotal: 5m 30s\tremaining: 2m 7s\n",
            "361:\tlearn: 0.0001180\ttotal: 5m 31s\tremaining: 2m 6s\n",
            "362:\tlearn: 0.0001180\ttotal: 5m 32s\tremaining: 2m 5s\n",
            "363:\tlearn: 0.0001180\ttotal: 5m 33s\tremaining: 2m 4s\n",
            "364:\tlearn: 0.0001180\ttotal: 5m 33s\tremaining: 2m 3s\n",
            "365:\tlearn: 0.0001180\ttotal: 5m 34s\tremaining: 2m 2s\n",
            "366:\tlearn: 0.0001180\ttotal: 5m 35s\tremaining: 2m 1s\n",
            "367:\tlearn: 0.0001180\ttotal: 5m 36s\tremaining: 2m\n",
            "368:\tlearn: 0.0001180\ttotal: 5m 37s\tremaining: 1m 59s\n",
            "369:\tlearn: 0.0001180\ttotal: 5m 38s\tremaining: 1m 58s\n",
            "370:\tlearn: 0.0001180\ttotal: 5m 39s\tremaining: 1m 58s\n",
            "371:\tlearn: 0.0001180\ttotal: 5m 40s\tremaining: 1m 57s\n",
            "372:\tlearn: 0.0001179\ttotal: 5m 41s\tremaining: 1m 56s\n",
            "373:\tlearn: 0.0001179\ttotal: 5m 42s\tremaining: 1m 55s\n",
            "374:\tlearn: 0.0001178\ttotal: 5m 43s\tremaining: 1m 54s\n",
            "375:\tlearn: 0.0001178\ttotal: 5m 43s\tremaining: 1m 53s\n",
            "376:\tlearn: 0.0001176\ttotal: 5m 44s\tremaining: 1m 52s\n",
            "377:\tlearn: 0.0001176\ttotal: 5m 45s\tremaining: 1m 51s\n",
            "378:\tlearn: 0.0001176\ttotal: 5m 46s\tremaining: 1m 50s\n",
            "379:\tlearn: 0.0001176\ttotal: 5m 47s\tremaining: 1m 49s\n",
            "380:\tlearn: 0.0001176\ttotal: 5m 48s\tremaining: 1m 48s\n",
            "381:\tlearn: 0.0001175\ttotal: 5m 49s\tremaining: 1m 47s\n",
            "382:\tlearn: 0.0001173\ttotal: 5m 50s\tremaining: 1m 47s\n",
            "383:\tlearn: 0.0001173\ttotal: 5m 51s\tremaining: 1m 46s\n",
            "384:\tlearn: 0.0001173\ttotal: 5m 52s\tremaining: 1m 45s\n",
            "385:\tlearn: 0.0001171\ttotal: 5m 53s\tremaining: 1m 44s\n",
            "386:\tlearn: 0.0001168\ttotal: 5m 53s\tremaining: 1m 43s\n",
            "387:\tlearn: 0.0001167\ttotal: 5m 54s\tremaining: 1m 42s\n",
            "388:\tlearn: 0.0001167\ttotal: 5m 55s\tremaining: 1m 41s\n",
            "389:\tlearn: 0.0001167\ttotal: 5m 56s\tremaining: 1m 40s\n",
            "390:\tlearn: 0.0001167\ttotal: 5m 57s\tremaining: 1m 39s\n",
            "391:\tlearn: 0.0001167\ttotal: 5m 58s\tremaining: 1m 38s\n",
            "392:\tlearn: 0.0001167\ttotal: 5m 59s\tremaining: 1m 37s\n",
            "393:\tlearn: 0.0001163\ttotal: 6m\tremaining: 1m 36s\n",
            "394:\tlearn: 0.0001162\ttotal: 6m 1s\tremaining: 1m 36s\n",
            "395:\tlearn: 0.0001162\ttotal: 6m 2s\tremaining: 1m 35s\n",
            "396:\tlearn: 0.0001162\ttotal: 6m 3s\tremaining: 1m 34s\n",
            "397:\tlearn: 0.0001162\ttotal: 6m 4s\tremaining: 1m 33s\n",
            "398:\tlearn: 0.0001162\ttotal: 6m 4s\tremaining: 1m 32s\n",
            "399:\tlearn: 0.0001161\ttotal: 6m 5s\tremaining: 1m 31s\n",
            "400:\tlearn: 0.0001159\ttotal: 6m 6s\tremaining: 1m 30s\n",
            "401:\tlearn: 0.0001159\ttotal: 6m 7s\tremaining: 1m 29s\n",
            "402:\tlearn: 0.0001159\ttotal: 6m 8s\tremaining: 1m 28s\n",
            "403:\tlearn: 0.0001155\ttotal: 6m 9s\tremaining: 1m 27s\n",
            "404:\tlearn: 0.0001155\ttotal: 6m 10s\tremaining: 1m 26s\n",
            "405:\tlearn: 0.0001155\ttotal: 6m 11s\tremaining: 1m 25s\n",
            "406:\tlearn: 0.0001154\ttotal: 6m 12s\tremaining: 1m 25s\n",
            "407:\tlearn: 0.0001154\ttotal: 6m 13s\tremaining: 1m 24s\n",
            "408:\tlearn: 0.0001154\ttotal: 6m 14s\tremaining: 1m 23s\n",
            "409:\tlearn: 0.0001154\ttotal: 6m 14s\tremaining: 1m 22s\n",
            "410:\tlearn: 0.0001154\ttotal: 6m 15s\tremaining: 1m 21s\n",
            "411:\tlearn: 0.0001154\ttotal: 6m 16s\tremaining: 1m 20s\n",
            "412:\tlearn: 0.0001154\ttotal: 6m 17s\tremaining: 1m 19s\n",
            "413:\tlearn: 0.0001154\ttotal: 6m 18s\tremaining: 1m 18s\n",
            "414:\tlearn: 0.0001154\ttotal: 6m 19s\tremaining: 1m 17s\n",
            "415:\tlearn: 0.0001154\ttotal: 6m 20s\tremaining: 1m 16s\n",
            "416:\tlearn: 0.0001154\ttotal: 6m 21s\tremaining: 1m 15s\n",
            "417:\tlearn: 0.0001154\ttotal: 6m 22s\tremaining: 1m 14s\n",
            "418:\tlearn: 0.0001154\ttotal: 6m 23s\tremaining: 1m 14s\n",
            "419:\tlearn: 0.0001154\ttotal: 6m 24s\tremaining: 1m 13s\n",
            "420:\tlearn: 0.0001154\ttotal: 6m 24s\tremaining: 1m 12s\n",
            "421:\tlearn: 0.0001150\ttotal: 6m 25s\tremaining: 1m 11s\n",
            "422:\tlearn: 0.0001150\ttotal: 6m 26s\tremaining: 1m 10s\n",
            "423:\tlearn: 0.0001150\ttotal: 6m 27s\tremaining: 1m 9s\n",
            "424:\tlearn: 0.0001149\ttotal: 6m 28s\tremaining: 1m 8s\n",
            "425:\tlearn: 0.0001149\ttotal: 6m 29s\tremaining: 1m 7s\n",
            "426:\tlearn: 0.0001141\ttotal: 6m 30s\tremaining: 1m 6s\n",
            "427:\tlearn: 0.0001140\ttotal: 6m 31s\tremaining: 1m 5s\n",
            "428:\tlearn: 0.0001140\ttotal: 6m 32s\tremaining: 1m 4s\n",
            "429:\tlearn: 0.0001140\ttotal: 6m 33s\tremaining: 1m 4s\n",
            "430:\tlearn: 0.0001139\ttotal: 6m 34s\tremaining: 1m 3s\n",
            "431:\tlearn: 0.0001133\ttotal: 6m 35s\tremaining: 1m 2s\n",
            "432:\tlearn: 0.0001131\ttotal: 6m 35s\tremaining: 1m 1s\n",
            "433:\tlearn: 0.0001130\ttotal: 6m 36s\tremaining: 1m\n",
            "434:\tlearn: 0.0001130\ttotal: 6m 37s\tremaining: 59.4s\n",
            "435:\tlearn: 0.0001128\ttotal: 6m 38s\tremaining: 58.5s\n",
            "436:\tlearn: 0.0001127\ttotal: 6m 39s\tremaining: 57.6s\n",
            "437:\tlearn: 0.0001127\ttotal: 6m 40s\tremaining: 56.7s\n",
            "438:\tlearn: 0.0001126\ttotal: 6m 41s\tremaining: 55.8s\n",
            "439:\tlearn: 0.0001126\ttotal: 6m 42s\tremaining: 54.9s\n",
            "440:\tlearn: 0.0001126\ttotal: 6m 43s\tremaining: 54s\n",
            "441:\tlearn: 0.0001126\ttotal: 6m 44s\tremaining: 53s\n",
            "442:\tlearn: 0.0001124\ttotal: 6m 45s\tremaining: 52.1s\n",
            "443:\tlearn: 0.0001124\ttotal: 6m 46s\tremaining: 51.2s\n",
            "444:\tlearn: 0.0001124\ttotal: 6m 46s\tremaining: 50.3s\n",
            "445:\tlearn: 0.0001124\ttotal: 6m 47s\tremaining: 49.4s\n",
            "446:\tlearn: 0.0001124\ttotal: 6m 48s\tremaining: 48.5s\n",
            "447:\tlearn: 0.0001124\ttotal: 6m 49s\tremaining: 47.6s\n",
            "448:\tlearn: 0.0001124\ttotal: 6m 50s\tremaining: 46.6s\n",
            "449:\tlearn: 0.0001124\ttotal: 6m 51s\tremaining: 45.7s\n",
            "450:\tlearn: 0.0001124\ttotal: 6m 52s\tremaining: 44.8s\n",
            "451:\tlearn: 0.0001124\ttotal: 6m 53s\tremaining: 43.9s\n",
            "452:\tlearn: 0.0001124\ttotal: 6m 54s\tremaining: 43s\n",
            "453:\tlearn: 0.0001124\ttotal: 6m 55s\tremaining: 42.1s\n",
            "454:\tlearn: 0.0001124\ttotal: 6m 56s\tremaining: 41.1s\n",
            "455:\tlearn: 0.0001124\ttotal: 6m 56s\tremaining: 40.2s\n",
            "456:\tlearn: 0.0001124\ttotal: 6m 57s\tremaining: 39.3s\n",
            "457:\tlearn: 0.0001123\ttotal: 6m 58s\tremaining: 38.4s\n",
            "458:\tlearn: 0.0001123\ttotal: 6m 59s\tremaining: 37.5s\n",
            "459:\tlearn: 0.0001123\ttotal: 7m\tremaining: 36.6s\n",
            "460:\tlearn: 0.0001121\ttotal: 7m 1s\tremaining: 35.7s\n",
            "461:\tlearn: 0.0001120\ttotal: 7m 2s\tremaining: 34.7s\n",
            "462:\tlearn: 0.0001119\ttotal: 7m 3s\tremaining: 33.8s\n",
            "463:\tlearn: 0.0001119\ttotal: 7m 4s\tremaining: 32.9s\n",
            "464:\tlearn: 0.0001119\ttotal: 7m 5s\tremaining: 32s\n",
            "465:\tlearn: 0.0001119\ttotal: 7m 6s\tremaining: 31.1s\n",
            "466:\tlearn: 0.0001118\ttotal: 7m 6s\tremaining: 30.2s\n",
            "467:\tlearn: 0.0001112\ttotal: 7m 7s\tremaining: 29.3s\n",
            "468:\tlearn: 0.0001110\ttotal: 7m 8s\tremaining: 28.3s\n",
            "469:\tlearn: 0.0001109\ttotal: 7m 9s\tremaining: 27.4s\n",
            "470:\tlearn: 0.0001105\ttotal: 7m 10s\tremaining: 26.5s\n",
            "471:\tlearn: 0.0001104\ttotal: 7m 11s\tremaining: 25.6s\n",
            "472:\tlearn: 0.0001104\ttotal: 7m 12s\tremaining: 24.7s\n",
            "473:\tlearn: 0.0001104\ttotal: 7m 13s\tremaining: 23.8s\n",
            "474:\tlearn: 0.0001104\ttotal: 7m 14s\tremaining: 22.9s\n",
            "475:\tlearn: 0.0001104\ttotal: 7m 15s\tremaining: 21.9s\n",
            "476:\tlearn: 0.0001104\ttotal: 7m 16s\tremaining: 21s\n",
            "477:\tlearn: 0.0001104\ttotal: 7m 17s\tremaining: 20.1s\n",
            "478:\tlearn: 0.0001104\ttotal: 7m 18s\tremaining: 19.2s\n",
            "479:\tlearn: 0.0001104\ttotal: 7m 18s\tremaining: 18.3s\n",
            "480:\tlearn: 0.0001104\ttotal: 7m 19s\tremaining: 17.4s\n",
            "481:\tlearn: 0.0001095\ttotal: 7m 20s\tremaining: 16.5s\n",
            "482:\tlearn: 0.0001095\ttotal: 7m 21s\tremaining: 15.5s\n",
            "483:\tlearn: 0.0001095\ttotal: 7m 22s\tremaining: 14.6s\n",
            "484:\tlearn: 0.0001095\ttotal: 7m 23s\tremaining: 13.7s\n",
            "485:\tlearn: 0.0001095\ttotal: 7m 24s\tremaining: 12.8s\n",
            "486:\tlearn: 0.0001095\ttotal: 7m 25s\tremaining: 11.9s\n",
            "487:\tlearn: 0.0001095\ttotal: 7m 26s\tremaining: 11s\n",
            "488:\tlearn: 0.0001095\ttotal: 7m 27s\tremaining: 10.1s\n",
            "489:\tlearn: 0.0001095\ttotal: 7m 28s\tremaining: 9.14s\n",
            "490:\tlearn: 0.0001095\ttotal: 7m 28s\tremaining: 8.23s\n",
            "491:\tlearn: 0.0001095\ttotal: 7m 29s\tremaining: 7.31s\n",
            "492:\tlearn: 0.0001095\ttotal: 7m 30s\tremaining: 6.4s\n",
            "493:\tlearn: 0.0001095\ttotal: 7m 31s\tremaining: 5.49s\n",
            "494:\tlearn: 0.0001095\ttotal: 7m 32s\tremaining: 4.57s\n",
            "495:\tlearn: 0.0001095\ttotal: 7m 33s\tremaining: 3.66s\n",
            "496:\tlearn: 0.0001089\ttotal: 7m 34s\tremaining: 2.74s\n",
            "497:\tlearn: 0.0001089\ttotal: 7m 35s\tremaining: 1.83s\n",
            "498:\tlearn: 0.0001085\ttotal: 7m 36s\tremaining: 914ms\n",
            "499:\tlearn: 0.0001085\ttotal: 7m 37s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7ff594d50be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "styc7msT1MI6",
        "colab_type": "text"
      },
      "source": [
        "**Оптимальная глубина такая же как и AdaBoost Sklearn, обучение довольно быстрое но даже при 500 итерациях не догоняет sklearn, хотя очень близко**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuExn6ixMOeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57a90ed1-0d27-4e63-809d-2852bb39d1d5"
      },
      "source": [
        "y_pred = model.predict(test_datasetQO[:, 0:784])\n",
        "y_proba = model.predict_proba(test_datasetQO[:, 0:784])[:, 1]\n",
        "y_test = test_datasetQO[:, -1]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9685\n",
            "ROC AUC: 0.9946330000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prqcj-gVzTGV",
        "colab_type": "text"
      },
      "source": [
        "AdaBoost Accuracy: 0.9735"
      ]
    }
  ]
}